= Testing

== shift-left testing 
teams apply shift-left testing to help build quality into applications as early as possible. Shift-left testing means bringing 
testing analysis earlier into the development process, ideally around the point at which 
ideas are being discussed and details clarified. This process results in many questions 
being asked that help us identify issues earlier, deliver valuable features, and improve 
the quality of our products. Shift-left activities are an invaluable approach to improving 
quality and should be encouraged.

Shift-left testing is
a strategy to move testing activities earlier in the software development lifecycle (SDLC), shifting them "left" on the timeline from a late, separate phase to integrated parts of planning, design, and coding. The core idea is to find and fix defects sooner, making them cheaper and easier to resolve, which leads to higher quality, faster delivery, better collaboration, and reduced costs by preventing issues from propagating, supporting Agile and DevOps. 
How it works

* Early involvement: Testers and QA engage from the requirements/discovery phase, analyzing user stories and acceptance criteria for testability and clarity.
* Developer ownership: Developers write and run tests (like unit and integration tests) concurrently with coding, not after.
* Continuous feedback: Testers provide rapid feedback to developers, creating short feedback loops for quick adjustments.
* Automation: Security and functional tests are automated and integrated into CI/CD pipelines, running frequently. 

Shift-left testing means moving testing activities earlier ("to the left") in the software development lifecycle instead of waiting until the end.  

The main goal is to find defects as early as possible, when they are cheaper and easier to fix.

=== Traditional vs Shift-Left Testing

==== Traditional (Right-heavy testing)
----
Requirements → Design → Code → Test → Release
                               ↑
                           Most testing here
----

==== Shift-Left Testing
----
Requirements → Design → Code → Test → Release
   ↑            ↑         ↑
 Testing     Testing   Testing
----

Testing is no longer a separate phase; it becomes a continuous activity throughout development.

=== What Gets Shifted Left?

[cols="1,1,1", options="header"]
|===
| Phase | Traditional Testing | Shift-Left Testing
| Requirements | Rarely tested | Reviews, acceptance criteria, examples
| Design | Mostly ignored | Design reviews, threat modeling
| Coding | Manual testing later | Unit tests, static analysis
| Integration | Late discovery | Contract and integration tests early
|===

=== Practical Examples

==== Example 1: Requirements Testing (Before Code Exists)

*Feature*: User password reset

Traditional approach:
- Requirements are written
- Code is implemented
- QA later finds ambiguity (e.g., what happens if the email does not exist)

Shift-left approach:
- Tester reviews requirements before coding
- Questions are raised early:
  * What if the email is invalid?
  * Is there rate limiting?
  * What are the security expectations?

Example acceptance criteria:
----
Given an unregistered email
When a password reset is requested
Then the system responds with a generic success message
----

Result:
- Clear requirements
- Fewer changes during development

==== Example 2: Unit Testing During Coding

Traditional approach:
----
def divide(a, b):
    return a / b
----

Bug (division by zero) is found late.

Shift-left approach:
----
def divide(a, b):
    if b == 0:
        raise ValueError("Cannot divide by zero")
    return a / b
----

Unit test:
----
def test_divide_by_zero():
    with pytest.raises(ValueError):
        divide(10, 0)
----

Result:
- Defect detected during development
- No late-stage failures

==== Example 3: API Contract Testing (Before Frontend Exists)

Traditional approach:
- Backend and frontend are developed independently
- Integration breaks due to mismatched fields

Shift-left approach:
- API contract is defined first (e.g., OpenAPI)
- Tests validate the response structure early

Example contract:
----
{
  "id": "integer",
  "email": "string",
  "created_at": "ISO-8601"
}
----

Result:
- No integration surprises
- Clear agreement between teams

==== Example 4: Early Security Testing

*Feature*: File upload

Shift-left security considerations:
- Allowed file types
- Maximum file size
- Malware scanning
- Path traversal risks

Early tests:
- Upload forbidden file extensions
- Upload files with suspicious names (e.g., ../../etc/passwd)

Result:
- Security vulnerabilities removed before release

=== Shift-Left Testing in Agile and CI/CD

Typical CI pipeline with shift-left principles:
----
Commit →
  Static Code Analysis →
  Unit Tests →
  API Tests →
  Integration Tests →
  UI Tests →
Deploy
----

Most tests are automated and executed early.  
Manual exploratory testing focuses on high-risk areas instead of basic checks.

=== Common Tools for Shift-Left Testing

[cols="1,1", options="header"]
|===
| Area | Tools
| Static Analysis | SonarQube, ESLint
| Unit Testing | PyTest, JUnit
| API Testing | Postman, REST Assured
| Contract Testing | Pact
| Security Testing | Snyk, OWASP ZAP
| Requirements & BDD | Gherkin
|===

=== Benefits of Shift-Left Testing

- Bugs are detected earlier
- Fixes are cheaper
- Faster release cycles
- Higher overall product quality
- Reduced release pressure

=== Common Pitfalls

- Over-automation without strategy
- Ignoring exploratory testing
- Treating testers only as script writers

Shift-left testing should complement, not replace, human exploration.

=== Summary

Shift-left testing is about testing earlier, smarter, and continuously throughout development rather than testing late and reacting to defects.


== Test-Driven Development
Test-Driven Development (TDD) is a software development process widely used in development to ensure code quality and reduce the time spent debugging. TDD is an agile 
approach to software development that emphasizes the iterative writing of tests before writing the 
actual code.  By writing automated tests 
before writing production code, developers can ensure that their code meets the desired specifications 
and can be easily modified and maintained over time.

The TDD process comprises three steps:

* ``Red``: In this initial phase, developers write a test for the functionality they aim to implement. 
Since there is no corresponding code yet, this test will initially fail, hence the term “Red” to 
indicate the failing state of the test.
* ``Green``: Following the Red phase, developers write the minimum amount of code necessary to 
make the test pass. This phase aims to quickly move from a failing test (Red) to a passing test 
(Green), focusing on satisfying the test’s conditions without necessarily optimizing the code.
* ``Refactor``: After successfully passing the test, the code is then improved and optimized. This 
phase involves refining the code’s design, structure, and efficiency while ensuring that the 
test remains green, i.e., continues to pass. Refactoring is crucial for enhancing code quality, 
maintainability, and performance without altering the external behavior of the code, as confirmed 
by the passing tests.

TDD is a dynamic methodology in software development that prioritizes incrementally creating tests 
before the code is implemented. The TDD process revolves around a structured sequence known as 
the red-green-refactor cycle, which consists of the following stages:

* ``Writing a failing test``: Initiate the cycle by crafting a test that intentionally fails. This test serves 
as a specification for the desired functionality.
* ``Prohibiting overly complex tests``: Emphasize the creation of tests that are only as intricate 
as necessary. Avoiding unnecessary complexity ensures that tests remain focused on specific 
functionalities, enhancing clarity and maintainability.
* ``Minimizing code implementation``: Write the minimum code required to pass the failing test. 
This minimalist approach ensures that code is dedicated to fulfilling the specified requirements.

These steps are cyclically repeated for each new functionality, ensuring that every part of the software 
is thoroughly tested and backed by tests, thereby promoting high code quality, reducing bugs, and 
facilitating confident refactoring.

The iterative nature of TDD unfolds as follows: writing a failing test, implementing the code to pass the 
test, and refactoring the code to enhance code design and maintainability. This iterative loop persists 
until the entire code base is complete.

TDD’s unique approach to writing tests before code execution serves a dual purpose. First, it guarantees 
code correctness by aligning with predefined test requirements. Second, it fosters the creation of clean, 
maintainable, and adaptable code. Developers are encouraged to adhere to best practices, resulting in 
code that is easily comprehensible, modifiable, and extensible throughout the software development 
life cycle.

=== The red-green-refactor cycle
The red-green-refactor cycle is a fundamental concept in TDD. It serves as a robust and systematic 
methodology in software development that offers developers a structured framework for incremental 
progress. This approach is designed to break down the development process into discrete, manageable
steps, guaranteeing code correctness and alignment with predefined test requirements. 

* ``Red – writing a failing test``:
The first step in the red-green-refactor cycle is to write a failing test. The test should define the 
desired behavior of the code and should be written in a way that it fails initially. This is called 
the “red” step because the test is expected to fail.
* ``Green – writing code to pass the test``:
The second step is to write the code that will make the test pass. The code should be minimal, 
and it should only be written to make the test pass. This is called the “green” step because the 
test is expected to pass.
* ``Refactor – improving code without changing functionality``:
Once the test has passed, the developer can refactor the code to enhance its design, readability, 
and maintainability by eliminating duplication, simplifying the code, and improving its readability. 
The key is to make improvements without altering the functionality covered by the test.

The red-green-refactor cycle has several benefits, including the following:

* Enhanced code quality: The red-green-refactor cycle ensures that the code is correct, reliable, 
and meets the requirements predefined in the tests
* Accelerated development: The red-green-refactor cycle allows developers to catch errors early 
in the development process, which saves time and reduces the cost of fixing bugs
* Better collaboration: The red-green-refactor cycle encourages collaboration between developers, 
testers, and other stakeholders, which improves communication and helps to ensure that 
everyone is on the same page
* Simplified maintenance: The red-green-refactor cycle produces code that is easier to maintain 
and extend, which reduces the cost and effort of future development
By using the red-green-refactor cycle, developers can build reliable, maintainable, and scalable 
software applications.

== Unit Testing
One of the fundamental principles of effective unit testing is writing descriptive test suites. By logically 
organizing your tests and using descriptive names, you make it easier for yourself and other developers 
to understand the purpose and behavior of each test.

A descriptive test suite is a collection of related test cases that focuses on a specific functionality or 
component of your code. It serves as a documentation tool and helps developers understand the 
purpose and behavior of each test. Descriptive test suites are essential for maintaining code quality, 
facilitating collaboration among team members, and ensuring that tests remain relevant and up-to-date 
over time. By investing time in creating descriptive test suites, you can improve the maintainability 
and readability of your test code.

== Choosing meaningful names
The first step in creating descriptive test suites is choosing meaningful names for your test suites and 
test cases. Use clear and concise language to describe the functionality or behavior being tested. Avoid 
ambiguous or generic names that don’t provide enough context. For example, instead of naming a test 
suite “Test Suite 1,” consider naming it “User Authentication Tests” to convey the purpose of the tests. 
Meaningful names make it easier for developers to locate specific tests and understand their purpose, 
even when revisiting the code base after a long time.

== Structuring test suites
Organizing your test suites in a logical and hierarchical structure is crucial for creating descriptive 
test suites in Jasmine. A well-structured test suite mirrors the structure of your code base, making 
it easier to locate and understand specific tests. Group related tests together to improve readability 
and maintainability. For example, if you are testing a user authentication module, create a test suite 
specifically for login functionality and another for registration. This separation helps you isolate and 
focus on specific features, making it easier to identify and resolve issues. Additionally, consider using 
nested describe blocks to further organize your tests hierarchically. 
[source,javascript,attributes]
----
describe("User Authentication", () => {
 describe("Login", () => {
 // Login-related test cases
 });
 describe("Registration", () => {
 // Registration-related test cases
 });
});
----

== Writing clear and concise test descriptions
Within each test case, write clear and concise descriptions that accurately describe the expected 
behavior. Use language that is easily understandable and avoids technical jargon whenever possible. 
A well-written test description should provide enough information for you and others to understand 
the purpose of the test without needing to dive into the implementation details. Consider using the 
“should” format to describe the expected behavior – for example, “should correctly calculate the total 
for a cart with multiple items.” By using descriptive language, future developers can quickly grasp the 
intent of the test and identify any deviations from the expected behavior.

In addition to the test description, it is also helpful to include comments within the test code to provide 
further clarification or context where needed. These comments can explain the reasoning behind 
certain assertions or provide additional information about the test scenario. However, it is important 
to strike a balance and avoid excessive commenting that may clutter the test code.

== Maintaining and updating descriptive test suites
Descriptive test suites are not a one-time effort but require ongoing maintenance and updates as the 
code base evolves. It is essential to review and update test suites regularly to ensure they remain relevant 
and accurate. When making changes to the code, developers should also update the corresponding 
tests to reflect the updated behavior. Additionally, if a test case becomes obsolete or redundant, it 
should be removed or refactored.

When updating test suites, it is crucial to keep their descriptive nature intact. If a test case needs 
significant changes, it may be beneficial to create a new test case with an appropriate description 
instead of modifying the existing one. This helps maintain the clarity and transparency of the test suite.

Let’s consider a simple scenario where we have a JavaScript function called calculateTotal that 
calculates the total price of items in a shopping cart. We want to write a test to ensure that the function 
returns the correct total when given a set of items with their respective prices:
[source,javascript,attributes]
----
// Function under test
function calculateTotal(items) {
 let total = 0;
 items.forEach(item => {
 total += item.price;
 });
 return total;
}
// Test suite
describe("calculateTotal function", () => {
 // Test case 1: Calculate total for an empty cart
 it("should return 0 for an empty cart", () => {
 const cart = [];
 const result = calculateTotal(cart);
 expect(result).toBe(0);
 });
 // Test case 2: Calculate total for a cart with multiple items
 it("should correctly calculate the total for a cart with multiple 
items", () => {
 const cart = [
 { name: "Item 1", price: 10 },
 { name: "Item 2", price: 15 },
 { name: "Item 3", price: 20 }
 ];
 const result = calculateTotal(cart);
 expect(result).toBe(45);
 });
});
----
the test suite, we have two test cases, and the descriptions of the test cases clearly state what behavior 
is being tested:

* The first test case, “should return 0 for an empty cart,” verifies that the function correctly handles 
an empty shopping cart and returns a total of 0
* The second test case, “should correctly calculate the total for a cart with multiple items,” tests the 
function with a cart containing multiple items and checks if the calculated total is as expected

By providing descriptive test case descriptions, other developers can easily understand the intent 
and behavior of each test. These descriptions act as documentation, making it easier to maintain and 
update the tests as the code base evolves.