= AI 
:figures: 11-development/04-AI


== AI development
Software developers thrive on certainty. When you give a program certain input, you
always get the same output. For ages, this pure deterministic logic was the heart and
soul of software.

But when you use AI-assisted programming tools, things get a bit topsy-turvy. Get‐
ting results is like rolling dice since everything works on probabilities. When you
prompt an AI tool to whip up some code, and even use the same prompt over multi‐
ple tries, you might get different results each time. Sure, it’s a bit of a head-scratcher at
first, but once you get the hang of it, it’s totally worth it. That’s why there is a chapter
on prompt engineering that will help with this new approach to programming.

A key theme of the evolution of programming languages is abstraction. This is a fancy
way of describing how systems get easier for developers to use. When the tedious
details are handled in the background, developers can focus on what matters most.
This has been a driving force of innovation, allowing for breakthroughs like the inter‐
net, cloud computing, mobile, and AI.

image::{figures}/the-abstraction-of-programming-languages-and-tools-has-evolved-over-the-decades.png[The abstraction of programming languages and tools has evolved over the decades]

AI is the big umbrella: it includes all systems that can pull off tasks with the flair of
human intelligence. Tucked within AI is machine learning (ML). Instead of marching
to the beat of explicit instructions, ML systems come up with insights based on heaps
of data. ML is generally based on complex algorithms, which allow for making pre‐
dictions or decisions without hardcoding.
Take a step deeper, and you get deep learning (DL), a tighter slice of ML that rolls
with neural networks stacked with hidden layers—hence the deep tag. These stacked
models have shown standout results in areas like image and speech recognition.
Within the corridors of deep learning, you’ll find generative AI (or GenAI). GenAI
models create new data that reflects their training data.
In the innermost circle sits LLMs, such as GPT-4, Gemini, Claude, and LLaMA 2.
These powerful models—often called “foundation models”—churn out human-esque
text based on cutting-edge algorithms and training on huge amounts of data.

== Generative AI
Generative AI is a branch of artificial intelligence (AI), which allows for the creation
of new and unique content. 

But generative AI is more than just LLMs. GenAI also has multimodal capabilities,
meaning the ability to create images, audio, and video.

Advocates of LLMs are celebrating that these types of AI tools have democratized
theuse of AI, allowing anyone to use it to get results. However, this democratization
is a double-edged sword. The nature in which we interact with LLMs can give us the
illu- sion that we’re talking with a machine that reasons in the same way we humans
do. But making that assumption can affect our ability to get the most out of an LLM.
So, to get the best results out of tools such as ChatGPT, we should know how they
work (at least in general terms) to better understand how they can fit into our
testing activities and how to extract the most value from them.

== LLM
Take out your phone and open a messaging app, or any other app that makes your 
keyboard appear. Above the keyboard, you’ll likely see a range of suggested words to 
insert into your message. For example, my keyboard offers the following suggestions: 
I, I am, and The. Selecting one of these options, such as I am, causes the suggestions to 
update. For me, it offered the options away, away for, and now. Selecting the option away
for once again updates the available options. So, how does the keyboard know which 
options to show?

In your keyboard, there is an AI model that behaves in a manner resembling LLMs. 
This description is an oversimplification, but at its core, the keyboard on your phone 
is applying the same machine learning approach as an LLM by using probability. Lan-
guage is a complex and fluid set of rules, meaning any attempt to codify relationships 
explicitly is almost impossible. So instead, a model is trained on massive data sets to 
implicitly learn the relationships in language and create a probability distribution that 
is used to predict what the next word might be. This can best be described by visualizing 
the options available from the keyboard example

image::{figures}/probability-distribution-in-action.png[Probability distribution in action]

As we can see, when we select the term I am, the model in our keyboard has been 
trained to assign probabilities to a vast range of words. Some of these will have a high 
probability of coming after I am, such as away, and some will have a low probability, 
such as sandalwood. As mentioned before, these probabilities come from a model 
that has completed a training process, known as unsupervised learning, in which vast 
amounts of data have been sent to an algorithm for processing. It’s from that training 
process that a model is created with complex weights and balances that provide the 
model with its predictive abilities.

Chances are good that if you play around with the predictive function on your key-
board, the output will differ from mine—even if we have the same phone and oper-
ating system. This is because once the model has been trained and is utilized in our 
phones, it’s still being fine-tuned by what we type into our phones. I travel for work, 
so I must let people know when I am away and when I’m available. (It is perhaps a 
damning indictment of my work–life balance!) So, words such as I am and away have 
an increased probability as they are words I use more regularly. This is known as Rein-
forcement Learning with Human Feedback, or RLHF.

comparing predictive messaging on a phone to an LLM is an oversimplifica-
tion, but the comparison holds true. LLMs also use unsupervised learning and RLHF. 
The difference, however, is that although an AI model on a phone can look at perhaps 
the last five words typed to predict the next, LLMs use cutting-edge techniques, such as
* Generative pretrained transformers (which is what makes the GPT abbreviation in ChatGPT)
* Powerful hardware infrastructure using thousands of servers
* Training data on a scale that would dwarf what our humble keyboard model will have been trained on

The output of LLMs, no matter how powerful, is 
probabilistic. LLMs are not a repository of information—there is structured knowl-
edge stored within them like we would see on the wider internet. This means that how 
it comes to conclusions differs from how we humans do (probability rather than expe-
rience), which is what makes them so powerful but also risky to use if we aren’t vigilant 
about how we use them.

At first glance, LLMs work by simply taking instructions from a user and responding with an answer using natural language.

LLMs (Large Language Models) are a type of AI model designed to understand and generate human-like text. They are trained on vast amounts of text data and can perform a variety of tasks, such as translation, summarization, and question answering.

A large language model is a type of artificial intelligence model that processes, understands, and generates 
human-like text based on the data it has been trained on. These models are a subset 
of deep learning and are particularly advanced in handling various aspects of natural 
language processing (NLP).

As the name implies, these models are “large” not just in terms of the physical size 
of the data they are trained on but also in the complexity and number of parameters. 
Modern LLMs like OpenAI’s GPT-4 have up to hundreds of billions of parameters.

Analyzing a wide range of internet texts, books, articles, and other forms of written communication to learn the structure, nuances, and complexities of human language.
Most LLMs use the Transformer architecture, a deep learning model that relies on 
self-attention mechanisms to weigh the importance of different words in a sentence 
regardless of their position. This allows LLMs to generate more contextually relevant 
text. A typical Transformer model consists of an encoder and a decoder, each composed of multiple layers.

LLMs are deep learning models that are good at providing natural language responses 
to natural language prompts. You can imagine simply describing what you need in 
plain English and receiving ready-to-integrate code

These tools also enhance your debugging efficiency by identifying patterns and suggesting fixes. Suppose you want your AI tool to analyze a block of code and flag potential memory leaks
or performance issues. You can describe the code's purpose and ask the AI to
review it for potential issues. The AI can then provide insights and suggestions based on its understanding of best practices and common pitfalls in coding.

Moreover, when it comes to refactoring, the AI can suggest optimizations that make 
your code cleaner and more efficient.

LLMs extend beyond mere code generation; they are sophisticated enough to assist 
in designing software architecture as well. This capability allows developers to engage 
with these models more creatively and strategically. For instance, rather than simply 
requesting specific snippets of code, a developer can describe the overall objectives or 
functional requirements of a system. The LLM can then propose various architectural 
designs, suggest design patterns, or outline an entire system’s structure. This approach 
not only saves significant time but also takes advantage of the AI’s extensive training 
to innovate and optimize solutions, potentially introducing efficiencies or ideas that 
the human developer may not have initially considered. This flexibility makes LLMs 
invaluable partners in the creative and iterative processes of software development. 

== When to use and when to avoid generative AI
=== When to use
* Enhancing productivity
+
Use AI to automate boilerplate code, generate documentation, or 
provide coding suggestions within your IDE.
* Learning and exploration
+
Employ AI to learn new programming languages or frameworks by 
generating example codes and explanations.
* Handling repetitive tasks
+
Use AI to handle repetitive software testing or data entry tasks, freeing up time for more complex problems.

=== When to avoid
There are, however, situations in which you should avoid using LLMs and generative 
AI tools such as ChatGPT and GitHub Copilot, mainly those related to data security 
and privacy protection. Using AI in environments with sensitive or proprietary data 
can risk unintended data leaks. There are several reasons for this, one of which is that 
part or all of the code is sent to the model as context, meaning at least part of your proprietary code may find its way outside of your firewall. There is a question as to whether 
it may be included in the training data for the next round of training. 

Another scenario in which you might limit your usage is when precision and expertise are required. Given that a feature of LLMs is their ability to add randomness to 
their output (sometimes referred to as hallucinations), the output may contain subtle 
variations from the true and right answer. For this reason, you should always verify the 
output before including it in your codebase. 

=== Use cases
* **Chatbots**: LLMs can power conversational agents that provide customer support or engage users in dialogue.
* **Content generation**: They can create articles, stories, or other written content based on prompts.
* **Code generation**: LLMs can assist in writing code snippets or even entire programs based on natural language descriptions.
=== Examples
* **OpenAI's GPT-3**: A state-of-the-art LLM that can generate human-like text and perform various language tasks.
* **Google's BERT**: A model designed for understanding the context of words in search queries, improving search results.
=== Resources
* [OpenAI GPT-3](https://openai.com/research/gpt-3)
* [Google BERT](https://arxiv.org/abs/1810.04805)
=== Code example
[source,python]
----
import openai
openai.api          
key = 'your-api-key'
response = openai.Completion.create(
    engine="text-davinci-003",
    prompt="Write a short story about a robot learning to love.",
    max_tokens=100
)
print(response.choices[0].text.strip())
----

==  comparison of ChatGPT, Copilot, and CodeWhisperer
The first dimension we will consider is the engagement model: how we engage with 
AI. In the case of ChatGPT, we log in to the chat website and enter prompts into a chat 
input box. Then we refine our requirements in subsequent prompts. The feedback 
loop takes the context from the previous prompts, applies it to the current prompt, 
and generates output to which the user reacts and refires. If we contrast this engagement model against that of Copilot and CodeWhisperer, we note that the latter two 
tools work within an IDE. We can’t use it outside our IDE, try as we may. The approach 
is not inherently inferior; it just differs. 

The way that Copilot and CodeWhisperer keep you in your IDE can be seen as a benefit rather than a deficiency. In later chapters, we will get acquainted with Copilot Chat, 
the best of both worlds: ChatGPT and GPT-4, all in your IDE. These tools keep you in 
your code without distraction for longer. Working distraction-free is one of the keys to 
productivity. Copilot and CodeWhisperer excel at getting out of your way, keeping you 
from switching contexts, freeing you from distraction, and keeping you in the flow state 
longer. They do this well. You engage ChatGPT in a dialog; Copilot and CodeWhisperer 
advise you. The dialog takes longer; advice comes fast and free. 
Next, we will examine how the code is presented and generated. ChatGPT can create 
the code as a block, method, class, or project. ChatGPT reveals projects deliberatively 
if asked. But it does create the project behind the scenes. ChatGPT, after all, likes to 
talk. With Copilot and CodeWhisperer, the code unfolds one method at a time, at least 
initially. As you use these tools more, you will notice that they can write more and more 
of the code for a given class. But unfortunately, they can’t write an entire project with a 
tiny prompt. 

One item that they all share is their ability to respond to prompts. With ChatGPT, 
prompts are the only way to engage with the tool. With Copilot and CodeWhisperer, responding to prompts is not strictly necessary, but coding such prompts will make the 
output correspond more closely to what you initially had in mind.

Combining these factors, you may conclude that ChatGPT is an excellent choice for 
exploration and prototyping. However, ChatGPT can introduce unnecessary distractions, partly because you have left your IDE and are now in a web browser with all of the 
accompanying temptations that come with it. ChatGPT itself is part of the inclusion of 
unnecessary distractions. You will eventually fall into the proverbial rabbit hole. The 
tool makes it too easy not to. Don’t let that scare you off. It is a beautiful resource. 

Copilot and CodeWhisperer require that you have a desired outcome in mind. 
Therefore, these tools are perfect for when you want to go head down, coding with 
precise requirements and tight deadlines. Copilot and CodeWhisperer work best when 
you know the language and the framework. They can automate much of the drudgery, 
allowing you to focus on the business requirements, which add value and are likely why 
you are writing the software in the first place.

image::{figures}/comparison-of-chat-gpt-copilot-code-whisperer.png[A comparison of the positives and negatives of ChatGPT, Copilot, and CodeWhisperer]

=== Further reading
* [Understanding LLMs](https://www.example.com/understanding-llms)
* [Applications of LLMs](https://www.example.com/applications-of-llms)

=== Related topics
* [Natural Language Processing (NLP)](https://www.example.com/nlp)
* [Machine Learning (ML)](https://www.example.com/machine-learning)

=== Challenges
* **Bias**: LLMs can inherit biases present in the training data, leading to biased outputs.
* **Resource-intensive**: Training and running LLMs require significant computational resources, making them expensive to deploy.

=== Future trends
* **Improved efficiency**: Research is ongoing to make LLMs more efficient, reducing the computational resources needed.    
