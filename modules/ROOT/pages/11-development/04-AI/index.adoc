= AI development
:figures: 11-development/04-AI

== LLM
LLMs (Large Language Models) are a type of AI model designed to understand and generate human-like text. They are trained on vast amounts of text data and can perform a variety of tasks, such as translation, summarization, and question answering.

A large language model
is a type of artificial intelligence model that processes, understands, and generates 
human-like text based on the data it has been trained on. These models are a subset 
of deep learning and are particularly advanced in handling various aspects of natural 
language processing (NLP).

As the name implies, these models are “large” not just in terms of the physical size 
of the data they are trained on but also in the complexity and number of parameters. 
Modern LLMs like OpenAI’s GPT-4 have up to hundreds of billions of parameters.

nalyzing a wide range of internet texts, books, articles, and other forms of written com-
munication to learn the structure, nuances, and complexities of human language.
Most LLMs use the Transformer architecture, a deep learning model that relies on 
self-attention mechanisms to weigh the importance of different words in a sentence 
regardless of their position. This allows LLMs to generate more contextually relevant 
text. A typical Transformer model consists of an encoder and a decoder, each com-
posed of multiple layers.


LLMs are deep learning models that are good at providing natural language responses 
to natural language prompts. You can imagine simply describing what you need in 
plain English and receiving ready-to-integrate code

These tools also enhance your debugging efficiency by identifying patterns and sug-
gesting fixes. Suppose you want your AI tool to analyze a block of code and flag poten-
tial memory leaks
or performance issues. You can describe the code's purpose and ask the AI to
review it for potential issues. The AI can then provide insights and suggestions based on its understanding of best practices and common pitfalls in coding.

Moreover, when it comes to refactoring, the AI can suggest optimizations that make 
your code cleaner and more efficient.

LLMs extend beyond mere code generation; they are sophisticated enough to assist 
in designing software architecture as well. This capability allows developers to engage 
with these models more creatively and strategically. For instance, rather than simply 
requesting specific snippets of code, a developer can describe the overall objectives or 
functional requirements of a system. The LLM can then propose various architectural 
designs, suggest design patterns, or outline an entire system’s structure. This approach 
not only saves significant time but also takes advantage of the AI’s extensive training 
to innovate and optimize solutions, potentially introducing efficiencies or ideas that 
the human developer may not have initially considered. This flexibility makes LLMs 
invaluable partners in the creative and iterative processes of software development. 

== When to use and when to avoid generative AI
=== When to use
* Enhancing productivity
+
Use AI to automate boilerplate code, generate documentation, or 
provide coding suggestions within your IDE.
* Learning and exploration
+
Employ AI to learn new programming languages or frameworks by 
generating example codes and explanations.
* Handling repetitive tasks
+
Use AI to handle repetitive software testing or data entry tasks, freeing up time for more complex problems.

=== When to avoid
There are, however, situations in which you should avoid using LLMs and generative 
AI tools such as ChatGPT and GitHub Copilot, mainly those related to data security 
and privacy protection. Using AI in environments with sensitive or proprietary data 
can risk unintended data leaks. There are several reasons for this, one of which is that 
part or all of the code is sent to the model as context, meaning at least part of your pro-
prietary code may find its way outside of your firewall. There is a question as to whether 
it may be included in the training data for the next round of training. 

Another scenario in which you might limit your usage is when precision and exper-
tise are required. Given that a feature of LLMs is their ability to add randomness to 
their output (sometimes referred to as hallucinations), the output may contain subtle 
variations from the true and right answer. For this reason, you should always verify the 
output before including it in your codebase. 

=== Use cases
* **Chatbots**: LLMs can power conversational agents that provide customer support or engage users in dialogue.
* **Content generation**: They can create articles, stories, or other written content based on prompts.
* **Code generation**: LLMs can assist in writing code snippets or even entire programs based on natural language descriptions.
=== Examples
* **OpenAI's GPT-3**: A state-of-the-art LLM that can generate human-like text and perform various language tasks.
* **Google's BERT**: A model designed for understanding the context of words in search queries, improving search results.
=== Resources
* [OpenAI GPT-3](https://openai.com/research/gpt-3)
* [Google BERT](https://arxiv.org/abs/1810.04805)
=== Code example
[source,python]
----
import openai
openai.api          
key = 'your-api-key'
response = openai.Completion.create(
    engine="text-davinci-003",
    prompt="Write a short story about a robot learning to love.",
    max_tokens=100
)
print(response.choices[0].text.strip())
----
== Key concepts
=== Prompt
a prompt refers to the input provided to the model to generate 
a response. It can be a single sentence, a paragraph, or even a longer text. It serves 
as the instruction or query to the model, guiding its response. Given the quality of 
the prompt and the context in which the model responds, it is essential always to be 
aware of the prompts you have issued in the current session. Therefore, starting with 
a new session every time you begin a new project is advised.

The purpose of the Persona Pattern is to design prompts that establish a spe-
cific persona or role for the AI to assume, which guides the model’s responses 
in a consistent and contextually appropriate manner. By adhering to a defined 
persona, the AI’s replies become more predictable and aligned with the user’s 
expectations.

Better prompts make for better output. You may be asking, what makes for 
a better prompt? Great question! General prompts produce general results. Specific 
prompts produce specific results. As we engage with large language models (LLMs) 
generally and ChatGPT specifically, we will go from general to specific, refining the output as we go. This is known as the Refinement Pattern in prompt engineering: iteratively 
refining or improving the prompt to get more accurate, relevant, or sophisticated 
responses.

The Refinement Pattern involves iteratively refining or improving the prompt 
to get more accurate, relevant, or sophisticated responses. It’s about going from 
general to specific, enhancing the output quality as the interaction progresses 
with large language models like ChatGPT.
=== Persona Pattern
The Persona Pattern is a technique used in prompt engineering where the model is instructed to adopt a specific persona or role. This helps guide the model's responses to align with the desired tone, style, or expertise level. For example, you might prompt the model to respond as a "software engineer" or "data scientist" to get more relevant and context-aware answers.

In the context of prompt engineering, mainly related 
to AI and LLMs, the Persona Pattern refers to a strategy of designing prompts that estab-
lish a specific persona or role for the AI to assume. This approach guides the model’s 
responses consistently and contextually appropriately. One of the key benefits of using 
the Persona Pattern is maintaining consistency in responses. Adhering to a defined per-
sona makes the AI’s replies more predictable and aligned with the user’s expectations. 

It bears repeating that when working with LLMs, even when applying personas, the 
same input will not always produce the same output. For this reason, your output may 
not match the following exactly, but hopefully it is similar. 

You can apply the Persona Pattern in either direction: you can tell the LLM to respond 
as though it were someone or something within a given role, or you can ask the LLM 
to assume that you are a certain persona. This can be very useful when you need to 
explain some code in simplified terms or are attempting to understand complex or 
complicated topics.

=== Examples of the Persona Pattern
* **The intern persona**: is often characterized by eagerness to learn, a basic to inter-
mediate level of knowledge in the field, and a willingness to take on various tasks 
for learning and experience. The intern may ask clarifying questions, seek guid-
ance, and demonstrate a proactive approach to problem-solving. They are often 
resourceful but may lack the deep expertise of more experienced professionals 
in the field. This persona is useful in scenarios where the AI needs to simulate a 
learning and growth-oriented mindset.
* **Software Engineer**: "You are a software engineer with expertise in Python. Explain how to implement a binary search algorithm."
* **Data Scientist**: "You are a data scientist specializing in machine learning. Describe the process of training a neural network."
* **Customer Support Agent**: "You are a customer support agent for a tech company. How would you handle a customer complaint about a faulty product?"
* **The teacher persona**: is characterized by a deep understanding of the subject matter, 
the ability to explain complex concepts in simple terms, and a patient and supportive
approach to helping others learn. The teacher may ask questions to gauge the 
learner’s understanding, provide examples and analogies, and encourage critical
thinking. They are often skilled at breaking down complex topics into manageable
parts and guiding learners through the learning process. This persona is useful in
scenarios where the AI needs to provide explanations, tutorials, or educational
content.
* **The mentor persona**: is characterized by a wealth of experience, a willingness to share
knowledge, and a supportive and encouraging approach to helping others grow.
The mentor may ask questions to understand the learner’s goals, provide feedback
and guidance, and share personal experiences and insights. They are often skilled at
helping others navigate challenges, build confidence, and develop their skills. This
persona is useful in scenarios where the AI needs to provide career advice, skill
development, or personal growth support.
* **The researcher persona**: is characterized by a deep curiosity, a methodical approach to
investigation, and a focus on evidence-based conclusions. The researcher may ask
questions to clarify the research question, gather data and information, and analyze
the results. They are often skilled at synthesizing complex information, identifying
patterns and trends, and drawing conclusions based on evidence. This persona is
useful in scenarios where the AI needs to provide research support, data analysis,      
or scientific inquiry.
* **The analyst persona**: is characterized by a keen eye for detail, a logical and systematic
approach to problem-solving, and a focus on data-driven insights. The analyst may
ask questions to clarify the problem, gather data and information, and analyze the
results. They are often skilled at identifying patterns, trends, and anomalies in data,
and drawing conclusions based on evidence. This persona is useful in scenarios where
the AI needs to provide data analysis, business intelligence, or decision support.
* **The designer persona**: is characterized by a creative and innovative approach to problem-
solving, a focus on aesthetics and user experience, and a willingness to experiment
and iterate. The designer may ask questions to clarify the design brief, gather
inspiration and ideas, and create prototypes and mockups. They are often skilled at
balancing form and function, and creating designs that are visually appealing and
user-friendly. This persona is useful in scenarios where the AI needs to provide
design support, user experience design, or creative problem-solving.
* **The project manager persona**: is characterized by strong organizational skills, a focus on
planning and execution, and a willingness to take charge of projects. The project
manager may ask questions to clarify the project scope, gather requirements and
resources, and create project plans and timelines. They are often skilled at
coordinating teams, managing risks, and ensuring that projects are delivered on
time and within budget. This persona is useful in scenarios where the AI needs to
provide project management support, team coordination, or process improvement.  

=== The Audience Persona Pattern
When you use the Persona Pattern in reverse, it is commonly referred to as the Audience Persona Pattern in the context of prompt engineering. This refers to a predefined 
profile or representation of the intended audience for a particular application or use 
case. It helps in tailoring the responses generated by LLMs to better suit the needs and 
expectations of a specific group of users or individuals. 

The Audience Persona Pattern is a variation of the Persona Pattern in prompt 
engineering. It involves defining a profile or representation of the intended 
audience for a particular application or use case, which helps tailor the responses 
generated by LLMs to better suit the needs and expectations of a specific group 
of users or individuals.
=== Examples of the Audience Persona Pattern
* **The beginner audience**: is characterized by limited knowledge and experience in a specific field.
They may require explanations that are simple, clear, and devoid of jargon. The
beginner audience may ask basic questions, seek step-by-step instructions, and
demonstrate a desire to learn and understand fundamental concepts. This persona
is useful in scenarios where the AI needs to provide foundational knowledge or
explanations.
* **The expert audience**: is characterized by a high level of knowledge and experience in a
specific field. They may require explanations that are detailed, technical, and
assume a deep understanding of the subject matter. The expert audience may ask
complex questions, seek advanced insights, and demonstrate a familiarity with
industry-specific terminology. This persona is useful in scenarios where the AI
needs to provide in-depth analysis or specialized knowledge.
* **The customer support audience**: is characterized by a need for assistance and problem-solving.
They may require explanations that are empathetic, clear, and focused on resolving
issues. The customer support audience may ask questions related to product
functionality, troubleshooting, and service inquiries. This persona is useful in
scenarios where the AI needs to provide support and guidance to users.  
* **The technical writer audience**: is characterized by a need for clear and concise documentation.
They may require explanations that are structured, well-organized, and easy to
follow. The technical writer audience may ask questions related to formatting,
style guidelines, and best practices for writing technical content. This persona is
useful in scenarios where the AI needs to assist in creating documentation or
technical content.

==  comparison of ChatGPT, Copilot, and CodeWhisperer
The first dimension we will consider is the engagement model: how we engage with 
AI. In the case of ChatGPT, we log in to the chat website and enter prompts into a chat 
input box. Then we refine our requirements in subsequent prompts. The feedback 
loop takes the context from the previous prompts, applies it to the current prompt, 
and generates output to which the user reacts and refires. If we contrast this engage-
ment model against that of Copilot and CodeWhisperer, we note that the latter two 
tools work within an IDE. We can’t use it outside our IDE, try as we may. The approach 
is not inherently inferior; it just differs. 

The way that Copilot and CodeWhisperer keep you in your IDE can be seen as a ben-
efit rather than a deficiency. In later chapters, we will get acquainted with Copilot Chat, 
the best of both worlds: ChatGPT and GPT-4, all in your IDE. These tools keep you in 
your code without distraction for longer. Working distraction-free is one of the keys to 
productivity. Copilot and CodeWhisperer excel at getting out of your way, keeping you 
from switching contexts, freeing you from distraction, and keeping you in the flow state 
longer. They do this well. You engage ChatGPT in a dialog; Copilot and CodeWhisperer 
advise you. The dialog takes longer; advice comes fast and free. 
Next, we will examine how the code is presented and generated. ChatGPT can create 
the code as a block, method, class, or project. ChatGPT reveals projects deliberatively 
if asked. But it does create the project behind the scenes. ChatGPT, after all, likes to 
talk. With Copilot and CodeWhisperer, the code unfolds one method at a time, at least 
initially. As you use these tools more, you will notice that they can write more and more 
of the code for a given class. But unfortunately, they can’t write an entire project with a 
tiny prompt. 

One item that they all share is their ability to respond to prompts. With ChatGPT, 
prompts are the only way to engage with the tool. With Copilot and CodeWhisperer, responding to prompts is not strictly necessary, but coding such prompts will make the 
output correspond more closely to what you initially had in mind.

Combining these factors, you may conclude that ChatGPT is an excellent choice for 
exploration and prototyping. However, ChatGPT can introduce unnecessary distrac-
tions, partly because you have left your IDE and are now in a web browser with all of the 
accompanying temptations that come with it. ChatGPT itself is part of the inclusion of 
unnecessary distractions. You will eventually fall into the proverbial rabbit hole. The 
tool makes it too easy not to. Don’t let that scare you off. It is a beautiful resource. 

Copilot and CodeWhisperer require that you have a desired outcome in mind. 
Therefore, these tools are perfect for when you want to go head down, coding with 
precise requirements and tight deadlines. Copilot and CodeWhisperer work best when 
you know the language and the framework. They can automate much of the drudgery, 
allowing you to focus on the business requirements, which add value and are likely why 
you are writing the software in the first place.

image::{figures}/comparison-of-chat-gpt-copilot-code-whisperer.png[A comparison of the positives and negatives of ChatGPT, Copilot, and CodeWhisperer]
=== Further reading
* [Understanding LLMs](https://www.example.com/understanding-llms)
* [Applications of LLMs](https://www.example.com/applications-of-llms)
=== Related topics
* [Natural Language Processing (NLP)](https://www.example.com/nlp)
* [Machine Learning (ML)](https://www.example.com/machine-learning)
=== Challenges
* **Bias**: LLMs can inherit biases present in the training data, leading to biased outputs.
* **Resource-intensive**: Training and running LLMs require significant computational resources, making them expensive to deploy.
=== Future trends
* **Improved efficiency**: Research is ongoing to make LLMs more efficient, reducing the computational resources needed.    
