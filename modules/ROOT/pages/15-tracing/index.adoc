= Tracing
:figures: 15-tracing

Event logs, health probes, and metrics provide a wide variety of valuable data for inferring the internal state of an application. However, none of them consider that cloud
native applications are distributed systems. A user request is likely to be processed by
multiple applications, but so far we have no way to correlate data across application
boundaries.

A simple way to solve that problem could be to generate an identifier for each
request at the edge of the system (a correlation ID), use it in event logs, and pass it over
to the other services involved. By using that correlation ID, we could fetch all log messages related to a particular transaction from multiple applications.

If we follow that idea further, we’ll get to distributed tracing, a technique for tracking requests as they flow through a distributed system, letting us localize where errors
occur and troubleshoot performance issues. 

A distributed tracing backend is responsible for aggregating, storing, and making traces searchable.

a mature event-driven system may have processes that span different microservices. Knowing what's going on with many concurrent users and multiple event chains might become an impossible task, especially when these chains have branches with multiple event types triggering the same action.To solve this problem, you need to correlate all actions and events within the same process chain. A simple way to do this is to inject the same identifier across all HTTP calls, RabbitMQ messages, and Java threads handling the different actions. Then, you can print this identifier in all the related logs.
Ideally, you should have a unique identifier per action, which is generated at the origin of the chain. Furthermore, it'd be better if you could propagate it transparently, without having to model this traceability concern explicitly in all the services.

In this pattern we record information (e.g. start time, end time) about the work (e.g. service requests) performed when handling the external request in a centralized service. This can be done by:

* Assigns each external request a unique external request id.
* Pass this external request id to all services that are involved in handling the request.
* Include the external request id while logging.
* Records information (e.g. start time, end time) about the requests and operations performed when handling a external request in a centralized service.

This instrumentation might be part of the functionality provided by a Microservice Chassis framework.

The drawback is aggregating and storing traces can require significant infrastructure.

There are three main concepts in distributed tracing:
+
* A trace represents the activities associated with a request or a transaction, identified uniquely by a trace ID. It’s composed of one or more spans across one or
more services.
* Each step of the request processing is called a span, characterized by start and
end timestamps and identified uniquely by the pair trace ID and span ID.
* Tags are metadata that provide additional information regarding the span context, such as the request URI, the username of the currently logged-in user, or
the tenant identifier.

For example in a Bookshop, you can fetch books through the gateway (Edge Service), and the request is then forwarded to Catalog Service. The trace related to handling such a request would involve these two applications and at least three spans:
+
* The first span is the step performed by Edge Service to accept the initial HTTP
request.
* The second span is the step performed by Edge Service to route the request to
Catalog Service.
* The third span is the step performed by Catalog Service to handle the routed
request.

There are multiple choices related to distributed tracing systems. 
+
* First, we must
choose the format and protocol we’ll use to generate and propagate traces. like  OpenTelemetry (also called OTel )
* Next we need to choose whether to use OpenTelemetry directly (with the OpenTelemetry Java instrumentation) or rely on a façade that instruments the code in a vendor-neutral way and integrates with different distributed tracing systems (such as
Spring Cloud Sleuth). 
* Once the applications are instrumented for distributed tracing, we’ll need a tool to
collect and store traces. In the Grafana observability stack, the distributed tracing
backend of choice is Tempo.

A few standards have emerged for implementing distributed tracing and defining
guidelines for generating and propagating traces and spans. OpenZipkin is the more
mature project (https://zipkin.io). OpenTracing and OpenCensus are more recent
projects that have tried to standardize ways of instrumenting application code to sup-
port distributed tracing. They are both deprecated now, since they joined forces to work
on OpenTelemetry: the ultimate framework to “instrument, generate, collect, and
export telemetry data (metrics, logs, and traces).” Tempo supports all those options.
Spring Cloud Sleuth (https://spring.io/projects/spring-cloud-sleuth) is a project that
provides auto-configuration for distributed tracing in Spring Boot applications. It takes
care of instrumenting commonly used libraries in Spring applications and provides an
abstraction layer on top of specific distributed tracing libraries. OpenZipkin is the
default choice.

Spring Cloud Sleuth will not be developed further once Spring Framework 6
and Spring Boot 3 are released. The Spring project donated the Sleuth core frame-
work to Micrometer and created a new Micrometer Tracing subproject aiming to pro-
vide a vendor-neutral façade for traces, similar to what Micrometer already does for
metrics. Micrometer Tracing will provide support for OpenZipkin and OpenTelemetry.
Based on Micrometer Tracing, code instrumentation will become a core aspect of all
Spring libraries as part of the Spring Observability initiative.

//TODO read https://docs.lightstep.com/docs/quick-start-infra-otel-first

== Examples

* https://github.com/spring-kb/tracing-spring-zipkin[Simple tracing using Spring and Zipkin Server]
