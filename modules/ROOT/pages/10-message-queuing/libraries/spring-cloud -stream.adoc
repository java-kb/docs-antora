= Spring Cloud Stream

Spring Cloud Stream is based on the publish and subscribe pattern, where a publisher publishes 
messages to topics and subscribers subscribe to topics they are interested in receiving messages from.

==  RabbitMQ and Kafka dependencies
To bring in Spring Cloud Stream and its binders for RabbitMQ and Kafka, we need to add the two 
starter dependencies known as spring-cloud-starter-stream-rabbit and spring-cloud-starterstream-kafka. We also need a test dependency, spring-cloud-stream::test-binder, to bring in test support. 

To specify what version of Spring Cloud we want to use, we first declare a variable for the version:

Next, we use the variable to set up dependency management for the specified Spring Cloud version, 
as seen here:

[tabs]
====
Maven::
+
[source, xml]
----
    <properties>
        <spring.cloud.version>2024.0.2</spring.cloud.version>
    </properties>
    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>org.springframework.cloud</groupId>
                <artifactId>spring-cloud-dependencies</artifactId>
                <version>${spring.cloud.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-starter-stream-kafka</artifactId>
            <version>${spring.cloud.version}</version>
        </dependency>
        <!--We
        also need a test dependency in the product-composite project,
        spring-cloud-stream::test-binder, to bring in test support-->
        <dependency>
            <groupId>org.springframework.cloud</groupId>
            <artifactId>spring-cloud-stream-test-support</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>
----

Gradle::
+
[source, gradle]
----
ext {
 springCloudVersion = "2022.0.1"
}
dependencyManagement {
 imports {
 mavenBom "org.springframework.cloud:spring-cloud-dependencies:${springCloudVersion}"
 }
}

dependencies {
 implementation 'org.springframework.cloud:spring-cloud-starter-stream-rabbit'
 implementation 'org.springframework.cloud:spring-cloud-starter-stream-kafka'
 testImplementation 'org.springframework.cloud:spring-cloud-stream::test-binder'
}
----
====

== StreamBridge
The programming model is based on a functional paradigm, where functions implementing one of 
the functional interfaces Supplier, Function, or Consumer in the java.util.function package can 
be chained together to perform decoupled event-based processing. To trigger such functional-based 
processing externally, from non-functional code, the helper class StreamBridge can be used.
For example, to publish the body of an HTTP request to a topic, we only have to write the following:
[source,java,attributes]
----
@Autowired
private StreamBridge streamBridge;
@PostMapping
void sampleCreateAPI(@RequestBody String body) {
 streamBridge.send("topic", body);
}
----

The helper class StreamBridge is used to trigger the processing. It will publish a message on a topic. A 
function that consumes events from a topic (not creating new events) can be defined by implementing 
the functional interface java.util.function.Consumer as:
[source,java,attributes]
----
@Bean
public Consumer<String> mySubscriber() {
 return s -> System.out.println("ML RECEIVED: " + s);
}
----

To tie the various functions together, we use configuration.

This programming model can be used independently of the messaging system used, for example, RabbitMQ or Apache Kafka!


== Defining topics and events
Messaging systems handle messages that typically consist of headers and a body. An event is a message 
that describes something that has happened. For events, the message body can be used to describe 
the type of event, the event data, and a timestamp for when the event occurred.

[tabs]
======

CaveatEmptor::
+
[tabs]
====

Country.java::
+
[source, java]
----
----
====

Cities API::
+
[tabs]
====
Country.java::
+
[source, java]
----
----
====

Multiplication microservices::
+
[source, java]
----
----

Microservices with Spring Boot 3 and Spring Cloud::
To implement the event-driven create and delete services, we will use Spring Cloud Stream.
+
We will use one topic per type of entity: products, recommendations, and reviews.
+
The event class we will use looks as follows:
+
* The Event class is a generic class parameterized over the types of its key and data fields, K and T
* The event type is declared as an enumerator with the allowed values, that is, CREATE and DELETE
* The class defines two constructors, one empty and one that can be used to initialize the type, 
key, and value members
* Finally, the class defines getter methods for its member variables
[tabs]
====
Event.java::
+
[source, java]
----
package se.magnus.api.event;

import static java.time.ZonedDateTime.now;

import com.fasterxml.jackson.databind.annotation.JsonSerialize;
import com.fasterxml.jackson.datatype.jsr310.ser.ZonedDateTimeSerializer;
import java.time.ZonedDateTime;

public class Event<K, T> {

  public enum Type {
    CREATE,
    DELETE
  }

  private final Type eventType;
  private final K key;
  private final T data;
  private final ZonedDateTime eventCreatedAt;

  public Event() {
    this.eventType = null;
    this.key = null;
    this.data = null;
    this.eventCreatedAt = null;
  }

  public Event(Type eventType, K key, T data) {
    this.eventType = eventType;
    this.key = key;
    this.data = data;
    this.eventCreatedAt = now();
  }

  public Type getEventType() {
    return eventType;
  }

  public K getKey() {
    return key;
  }

  public T getData() {
    return data;
  }

  @JsonSerialize(using = ZonedDateTimeSerializer.class)
  public ZonedDateTime getEventCreatedAt() {
    return eventCreatedAt;
  }
}
----
====

Polar Book Shop::
+
[source, java]
----
----
======

== Publishing events 
To be able to publish events in the composite service, we need to perform the following steps:

1. Publish events in the bussines layer
2. Add configuration for publishing events
3. Change tests so that they can test the publishing of events

[tabs]
======

CaveatEmptor::
+
[tabs]
====

Country.java::
+
[source, java]
----
----
====

Cities API::
+
[tabs]
====
Country.java::
+
[source, java]
----
----
====

Multiplication microservices::
+
[source, java]
----
----

Microservices with Spring Boot 3 and Spring Cloud::
+
When the composite service receives HTTP requests for the creation and deletion of composite products, it will publish the corresponding events to the core services on their topics. To be able to publish 
events in the composite service, we need to perform the following steps:
+
1. Publish events in the integration layer
2. Add configuration for publishing events
3. Change tests so that they can test the publishing of events
+
To publish an event in the integration layer, we need to:
+
1. Create an Event object based on the body in the HTTP request
2. Create a Message object where the Event object is used as the payload and the key field in the 
Event object is used as the partition key in the header
3. Use the helper class StreamBridge to publish the event on the desired topic
[tabs]
====
ProductCompositeIntegration.java::
from createProduct code, we can see:
• The integration layer implements the createProduct() method in the ProductService in-
terface by using a helper method, sendMessage(). The helper method takes the name of an 
output binding and an event object. The binding name products-out-0 will be bound to the 
topic of the product service in the configuration below.
• Since the sendMessage() uses blocking code, when calling streamBridge, it is executed on a 
thread provided by a dedicated scheduler, publishEventScheduler. This is the same approach 
as for handling blocking JPA code in the review microservice. See the section on Dealing with 
blocking code for details.
• The helper method, sendMessage(), creates a Message object and sets the payload and the 
partitionKey header as described above. Finally, it uses the streamBridge object to send the 
event to the messaging system, which will publish it on the topic defined in the configuration.

+
[source, java]
----
package se.magnus.microservices.composite.product.services;

import static java.util.logging.Level.FINE;
import static reactor.core.publisher.Flux.empty;
import static se.magnus.api.event.Event.Type.CREATE;
import static se.magnus.api.event.Event.Type.DELETE;

import com.fasterxml.jackson.databind.ObjectMapper;
import java.io.IOException;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.boot.actuate.health.Health;
import org.springframework.cloud.stream.function.StreamBridge;
import org.springframework.http.HttpStatus;
import org.springframework.messaging.Message;
import org.springframework.messaging.support.MessageBuilder;
import org.springframework.stereotype.Component;
import org.springframework.web.reactive.function.client.WebClient;
import org.springframework.web.reactive.function.client.WebClientResponseException;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;
import reactor.core.scheduler.Scheduler;
import se.magnus.api.core.product.Product;
import se.magnus.api.core.product.ProductService;
import se.magnus.api.core.recommendation.Recommendation;
import se.magnus.api.core.recommendation.RecommendationService;
import se.magnus.api.core.review.Review;
import se.magnus.api.core.review.ReviewService;
import se.magnus.api.event.Event;
import se.magnus.api.exceptions.InvalidInputException;
import se.magnus.api.exceptions.NotFoundException;
import se.magnus.util.http.HttpErrorInfo;

@Component
public class ProductCompositeIntegration implements ProductService, RecommendationService, ReviewService {

    private static final Logger LOG = LoggerFactory.getLogger(ProductCompositeIntegration.class);

    private final WebClient webClient;
    private final ObjectMapper mapper;

    private final String productServiceUrl;
    private final String recommendationServiceUrl;
    private final String reviewServiceUrl;

    private final StreamBridge streamBridge;

    private final Scheduler publishEventScheduler;

    @Autowired
    public ProductCompositeIntegration(
            @Qualifier("publishEventScheduler") Scheduler publishEventScheduler,

            WebClient.Builder webClient,
            ObjectMapper mapper,
            StreamBridge streamBridge,

            @Value("${app.product-service.host}") String productServiceHost,
            @Value("${app.product-service.port}") int productServicePort,

            @Value("${app.recommendation-service.host}") String recommendationServiceHost,
            @Value("${app.recommendation-service.port}") int recommendationServicePort,

            @Value("${app.review-service.host}") String reviewServiceHost,
            @Value("${app.review-service.port}") int reviewServicePort) {

        this.publishEventScheduler = publishEventScheduler;
        this.webClient = webClient.build();
        this.mapper = mapper;
        this.streamBridge = streamBridge;

        productServiceUrl = "http://" + productServiceHost + ":" + productServicePort;
        recommendationServiceUrl = "http://" + recommendationServiceHost + ":" + recommendationServicePort;
        reviewServiceUrl = "http://" + reviewServiceHost + ":" + reviewServicePort;
    }

    @Override
    public Mono<Product> createProduct(Product body) {

        return Mono.fromCallable(() -> {
            sendMessage("products-out-0", new Event(CREATE, body.getProductId(), body));
            return body;
        }).subscribeOn(publishEventScheduler);
    }

    @Override
    public Mono<Product> getProduct(int productId) {
        String url = productServiceUrl + "/product/" + productId;
        LOG.debug("Will call the getProduct API on URL: {}", url);

        return webClient.get().uri(url).retrieve().bodyToMono(Product.class).log(LOG.getName(), FINE)
                .onErrorMap(WebClientResponseException.class, ex -> handleException(ex));
    }

    @Override
    public Mono<Void> deleteProduct(int productId) {

        return Mono.fromRunnable(() -> sendMessage("products-out-0", new Event(DELETE, productId, null)))
                .subscribeOn(publishEventScheduler).then();
    }

    @Override
    public Mono<Recommendation> createRecommendation(Recommendation body) {

        return Mono.fromCallable(() -> {
            sendMessage("recommendations-out-0", new Event(CREATE, body.getProductId(), body));
            return body;
        }).subscribeOn(publishEventScheduler);
    }

    @Override
    public Flux<Recommendation> getRecommendations(int productId) {

        String url = recommendationServiceUrl + "/recommendation?productId=" + productId;

        LOG.debug("Will call the getRecommendations API on URL: {}", url);

        // Return an empty result if something goes wrong to make it possible for the
        // composite service to return partial responses
        return webClient.get().uri(url).retrieve().bodyToFlux(Recommendation.class).log(LOG.getName(), FINE)
                .onErrorResume(error -> empty());
    }

    @Override
    public Mono<Void> deleteRecommendations(int productId) {

        return Mono.fromRunnable(() -> sendMessage("recommendations-out-0", new Event(DELETE, productId, null)))
                .subscribeOn(publishEventScheduler).then();
    }

    @Override
    public Mono<Review> createReview(Review body) {

        return Mono.fromCallable(() -> {
            sendMessage("reviews-out-0", new Event(CREATE, body.getProductId(), body));
            return body;
        }).subscribeOn(publishEventScheduler);
    }

    @Override
    public Flux<Review> getReviews(int productId) {

        String url = reviewServiceUrl + "/review?productId=" + productId;

        LOG.debug("Will call the getReviews API on URL: {}", url);

        // Return an empty result if something goes wrong to make it possible for the
        // composite service to return partial responses
        return webClient.get().uri(url).retrieve().bodyToFlux(Review.class).log(LOG.getName(), FINE)
                .onErrorResume(error -> empty());
    }

    @Override
    public Mono<Void> deleteReviews(int productId) {

        return Mono.fromRunnable(() -> sendMessage("reviews-out-0", new Event(DELETE, productId, null)))
                .subscribeOn(publishEventScheduler).then();
    }

    public Mono<Health> getProductHealth() {
        return getHealth(productServiceUrl);
    }

    public Mono<Health> getRecommendationHealth() {
        return getHealth(recommendationServiceUrl);
    }

    public Mono<Health> getReviewHealth() {
        return getHealth(reviewServiceUrl);
    }

    private Mono<Health> getHealth(String url) {
        url += "/actuator/health";
        LOG.debug("Will call the Health API on URL: {}", url);
        return webClient.get().uri(url).retrieve().bodyToMono(String.class)
                .map(s -> new Health.Builder().up().build())
                .onErrorResume(ex -> Mono.just(new Health.Builder().down(ex).build()))
                .log(LOG.getName(), FINE);
    }

    private void sendMessage(String bindingName, Event event) {
        LOG.debug("Sending a {} message to {}", event.getEventType(), bindingName);
        Message message = MessageBuilder.withPayload(event)
                .setHeader("partitionKey", event.getKey())
                .build();
        streamBridge.send(bindingName, message);
    }

    private Throwable handleException(Throwable ex) {

        if (!(ex instanceof WebClientResponseException)) {
            LOG.warn("Got a unexpected error: {}, will rethrow it", ex.toString());
            return ex;
        }

        WebClientResponseException wcre = (WebClientResponseException) ex;

        switch (HttpStatus.resolve(wcre.getStatusCode().value())) {

            case NOT_FOUND:
                return new NotFoundException(getErrorMessage(wcre));

            case UNPROCESSABLE_ENTITY:
                return new InvalidInputException(getErrorMessage(wcre));

            default:
                LOG.warn("Got an unexpected HTTP error: {}, will rethrow it", wcre.getStatusCode());
                LOG.warn("Error body: {}", wcre.getResponseBodyAsString());
                return ex;
        }
    }

    private String getErrorMessage(WebClientResponseException ex) {
        try {
            return mapper.readValue(ex.getResponseBodyAsString(), HttpErrorInfo.class).getMessage();
        } catch (IOException ioex) {
            return ex.getMessage();
        }
    }
}
----

product-composite-service/src/main/resources/application.yml::
+
We also need to set up the configuration for the messaging system, to be able to publish events; this 
is similar to what we did for the consumers. Declaring RabbitMQ as the default messaging system, 
JSON as the default content type, and Kafka and RabbitMQ for connectivity information is the same 
as for the consumers.
+
In this configuration, we can see that:
+
• The configuration applies for the binding name products-out-0
• The partition key used will be taken from the message header partitionKey
• Two partitions will be used
[source, yml]
----
spring.cloud.stream:
  defaultBinder: rabbit
  default.contentType: application/json
  bindings:
    products-out-0:
      destination: products
      producer:
        required-groups: auditGroup
    recommendations-out-0:
      destination: recommendations
      producer:
        required-groups: auditGroup
    reviews-out-0:
      destination: reviews
      producer:
        required-groups: auditGroup

spring.cloud.stream.kafka.binder:
  brokers: 127.0.0.1
  defaultBrokerPort: 9092

spring.rabbitmq:
  host: 127.0.0.1
  port: 5672
  username: guest
  password: guest
---
spring.config.activate.on-profile: docker

server.port: 8080

app:
  product-service:
    host: product
    port: 8080
  recommendation-service:
    host: recommendation
    port: 8080
  review-service:
    host: review
    port: 8080


spring.rabbitmq.host: rabbitmq

spring.cloud.stream.kafka.binder.brokers: kafka
----
====

Polar Book Shop::
+
[source, java]
----
----
======

== Consuming events
To be able to consume events in the core services, we need to do the following:

• Declare message processors that consume events published on the core service’s topic
• Change our service implementations to use the reactive persistence layer
• Add configuration required for consuming events
• Change our tests so that they can test the asynchronous processing of the events

[tabs]
======

CaveatEmptor::
+
[tabs]
====

Country.java::
+
[source, java]
----
----
====

Cities API::
+
[tabs]
====
Country.java::
+
[source, java]
----
----
====

Multiplication microservices::
+
[source, java]
----
----

Microservices with Spring Boot 3 and Spring Cloud::
The REST APIs for creating and deleting entities have been replaced with a message processor in each 
core microservice that consumes create and delete events on each entity’s topic. To be able to consume 
messages that have been published to a topic, we need to declare a Spring Bean that implements the 
functional interface java.util.function.Consumer.
+

[tabs]
====
MessageProcessorConfig.java::
The message processor for the product service is declared as:
+
• The class is annotated with @Configuration, telling Spring to look for Spring beans in the class.
• We inject an implementation of the ProductService interface in the constructor. The 
productService bean contains the business logic to perform the actual creation and dele-
tions of the product entities.
• We declare the message processor as a Spring bean that implements the functional interface 
Consumer, accepting an event as an input parameter of type Event<Integer,Product>.
+
The implementation of the Consumer function looks like this:
+
• It takes an event of type Event<Integer,Product> as an input parameter
• Using a switch statement, based on the event type, it will either create or delete a product entity
• It uses the injected productService bean to perform the actual create and delete operation
• If the event type is neither create nor delete, an exception will be thrown
+
To ensure that we can propagate exceptions thrown by the productService bean back to the messag-
ing system, we call the block() method on the responses we get back from the productService bean. 
This ensures that the message processor waits for the productService bean to complete its creation 
or deletion in the underlying database. Without calling the block() method, we would not be able 
to propagate exceptions and the messaging system would not be able to re-queue a failed attempt or 
possibly move the message to a dead-letter queue; instead, the message would silently be dropped.
+
Calling a block() method is, in general, considered a bad practice from a performance 
and scalability perspective. But in this case, we will only handle a few incoming messages 
in parallel, one per partition, as described above. This means that we will only have a 
few threads blocked concurrently, which will not negatively impact the performance or 
the scalability.
+
We also need to set up a configuration for the messaging system to be able to consume events. To do 
this, we need to complete the following steps:
+
* We declare that RabbitMQ is the default messaging system and that the default content type is JSON: `defaultBinder: rabbit`
* Next, we bind the input to the message processors to specific topic names: `destination: products`
* Finally, we declare connectivity information for both Kafka and RabbitMQ
+
In the default Spring profile, we specify hostnames to be used when we run our system landscape 
without Docker on localhost with the IP address 127.0.0.1. In the docker Spring profile, we specify 
the hostnames we will use when running in Docker and using Docker Compose, that is, rabbitmq
and kafka.
+
Added to this configuration, the consumer configuration also specifies consumer groups, retry han-
dling, dead-letter queues, and partitions as they were described earlier in the Handling challenges with 
messaging section.
[source, java]
----
package se.magnus.microservices.core.product.services;

import java.util.function.Consumer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import se.magnus.api.core.product.Product;
import se.magnus.api.core.product.ProductService;
import se.magnus.api.event.Event;
import se.magnus.api.exceptions.EventProcessingException;

@Configuration
public class MessageProcessorConfig {

    private static final Logger LOG = LoggerFactory.getLogger(MessageProcessorConfig.class);

    private final ProductService productService;

    @Autowired
    public MessageProcessorConfig(ProductService productService) {
        this.productService = productService;
    }

    @Bean
    public Consumer<Event<Integer, Product>> messageProcessor() {
        return event -> {
            LOG.info("Process message created at {}...", event.getEventCreatedAt());

            switch (event.getEventType()) {

                case CREATE:
                    Product product = event.getData();
                    LOG.info("Create product with ID: {}", product.getProductId());
                    productService.createProduct(product).block();
                    break;

                case DELETE:
                    int productId = event.getKey();
                    LOG.info("Delete product with ProductID: {}", productId);
                    productService.deleteProduct(productId).block();
                    break;

                default:
                    String errorMessage = "Incorrect event type: " + event.getEventType()
                            + ", expected a CREATE or DELETE event";
                    LOG.warn(errorMessage);
                    throw new EventProcessingException(errorMessage);
            }

            LOG.info("Message processing done!");

        };
    }
}
----

recommendation/services/MessageProcessorConfig.java::
+
[source, java]
----
package se.magnus.microservices.core.recommendation.services;

import java.util.function.Consumer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import se.magnus.api.core.recommendation.Recommendation;
import se.magnus.api.core.recommendation.RecommendationService;
import se.magnus.api.event.Event;
import se.magnus.api.exceptions.EventProcessingException;

@Configuration
public class MessageProcessorConfig {

    private static final Logger LOG = LoggerFactory.getLogger(MessageProcessorConfig.class);

    private final RecommendationService recommendationService;

    @Autowired
    public MessageProcessorConfig(RecommendationService recommendationService) {
        this.recommendationService = recommendationService;
    }

    @Bean
    public Consumer<Event<Integer, Recommendation>> messageProcessor() {
        return event -> {

            LOG.info("Process message created at {}...", event.getEventCreatedAt());

            switch (event.getEventType()) {

                case CREATE:
                    Recommendation recommendation = event.getData();
                    LOG.info("Create recommendation with ID: {}/{}", recommendation.getProductId(),
                            recommendation.getRecommendationId());
                    recommendationService.createRecommendation(recommendation).block();
                    break;

                case DELETE:
                    int productId = event.getKey();
                    LOG.info("Delete recommendations with ProductID: {}", productId);
                    recommendationService.deleteRecommendations(productId).block();
                    break;

                default:
                    String errorMessage = "Incorrect event type: " + event.getEventType()
                            + ", expected a CREATE or DELETE event";
                    LOG.warn(errorMessage);
                    throw new EventProcessingException(errorMessage);
            }

            LOG.info("Message processing done!");
        };
    }
}
----

/review/services/MessageProcessorConfig.java::
+
[source, java]
----
package se.magnus.microservices.core.review.services;

import java.util.function.Consumer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import se.magnus.api.core.review.Review;
import se.magnus.api.core.review.ReviewService;
import se.magnus.api.event.Event;
import se.magnus.api.exceptions.EventProcessingException;

@Configuration
public class MessageProcessorConfig {

    private static final Logger LOG = LoggerFactory.getLogger(MessageProcessorConfig.class);

    private final ReviewService reviewService;

    @Autowired
    public MessageProcessorConfig(ReviewService reviewService) {
        this.reviewService = reviewService;
    }

    @Bean
    public Consumer<Event<Integer, Review>> messageProcessor() {
        return event -> {
            LOG.info("Process message created at {}...", event.getEventCreatedAt());

            switch (event.getEventType()) {

                case CREATE:
                    Review review = event.getData();
                    LOG.info("Create review with ID: {}/{}", review.getProductId(), review.getReviewId());
                    reviewService.createReview(review).block();
                    break;

                case DELETE:
                    int productId = event.getKey();
                    LOG.info("Delete reviews with ProductID: {}", productId);
                    reviewService.deleteReviews(productId).block();
                    break;

                default:
                    String errorMessage = "Incorrect event type: " + event.getEventType()
                            + ", expected a CREATE or DELETE event";
                    LOG.warn(errorMessage);
                    throw new EventProcessingException(errorMessage);
            }

            LOG.info("Message processing done!");
        };
    }
}
----

microservices/product-service/src/main/resources/application.yml::
+
[source, yml]
----
spring.cloud.function.definition: messageProcessor

spring.cloud.stream:
  defaultBinder: rabbit
  default.contentType: application/json
  bindings.messageProcessor-in-0:
    destination: products
    group: productsGroup

spring.cloud.stream.bindings.messageProcessor-in-0.consumer:
  maxAttempts: 3
  backOffInitialInterval: 500
  backOffMaxInterval: 1000
  backOffMultiplier: 2.0

spring.cloud.stream.rabbit.bindings.messageProcessor-in-0.consumer:
  autoBindDlq: true
  republishToDlq: true

spring.cloud.stream.kafka.bindings.messageProcessor-in-0.consumer:
  enableDlq: true

spring.cloud.stream.kafka.binder:
  brokers: 127.0.0.1
  defaultBrokerPort: 9092

spring.rabbitmq:
  host: 127.0.0.1
  port: 5672
  username: guest
  password: guest
---
spring.config.activate.on-profile: docker

server.port: 8080

spring.datasource:
  url: jdbc:postgresql://postgres/review-db

spring.rabbitmq.host: rabbitmq
spring.cloud.stream.kafka.binder.brokers: kafka
----

microservices/recommendation-service/src/main/resources/application.yml::
+
[source, yml]
----
spring.cloud.function.definition: messageProcessor

spring.cloud.stream:
  defaultBinder: rabbit
  default.contentType: application/json
  bindings.messageProcessor-in-0:
    destination: recommendations
    group: recommendationsGroup

spring.cloud.stream.bindings.messageProcessor-in-0.consumer:
  maxAttempts: 3
  backOffInitialInterval: 500
  backOffMaxInterval: 1000
  backOffMultiplier: 2.0

spring.cloud.stream.rabbit.bindings.messageProcessor-in-0.consumer:
  autoBindDlq: true
  republishToDlq: true

spring.cloud.stream.kafka.bindings.messageProcessor-in-0.consumer:
  enableDlq: true

spring.cloud.stream.kafka.binder:
  brokers: 127.0.0.1
  defaultBrokerPort: 9092

spring.rabbitmq:
  host: 127.0.0.1
  port: 5672
  username: guest
  password: guest
----

microservices/review-service/src/main/resources/application.yml::
+
[source, yml]
----
spring.cloud.function.definition: messageProcessor

spring.cloud.stream:
  defaultBinder: rabbit
  default.contentType: application/json
  bindings.messageProcessor-in-0:
    destination: reviews
    group: reviewsGroup

spring.cloud.stream.bindings.messageProcessor-in-0.consumer:
  maxAttempts: 3
  backOffInitialInterval: 500
  backOffMaxInterval: 1000
  backOffMultiplier: 2.0

spring.cloud.stream.rabbit.bindings.messageProcessor-in-0.consumer:
  autoBindDlq: true
  republishToDlq: true

spring.cloud.stream.kafka.bindings.messageProcessor-in-0.consumer:
  enableDlq: true

spring.cloud.stream.kafka.binder:
  brokers: 127.0.0.1
  defaultBrokerPort: 9092

spring.rabbitmq:
  host: 127.0.0.1
  port: 5672
  username: guest
  password: guest
----
====

Polar Book Shop::
+
[source, java]
----
----
======

== Testing
=== Testing Producer
Testing asynchronous event-driven microservices is, by its nature, difficult. Tests typically need to 
synchronize on the asynchronous background processing in some way to be able to verify the result. 
Spring Cloud Stream comes with support, in the form of a test binder, that can be used to verify what 
messages have been sent without using any messaging system during the tests!

The test support includes an OutputDestination helper class, which can be used to get the messages 
that were sent during a test.
[tabs]
======

CaveatEmptor::
+
[tabs]
====

Country.java::
+
[source, java]
----
----
====

Cities API::
+
[tabs]
====
Country.java::
+
[source, java]
----
----
====

Multiplication microservices::
+
[source, java]
----
----

Microservices with Spring Boot 3 and Spring Cloud::
+
A new test class, MessagingTests, has been added to run tests that verify 
that the expected messages are sent. Let’s go through the most important parts of the test class:
+
1. To be able to inject an OutputDestination bean in the test class, we also need to bring in 
its configuration from the class TestChannelBinderConfiguration.
2. Next, we declare a couple of helper methods for reading messages and also to be able to purge 
a topic. 
• The getMessage() method returns a message from a specified topic using the OutputDestination bean, named target
• The getMessages() method uses the getMessage() method to return all messages in a topic
• The purgeMessages() method uses the getMessages() method to purge a topic from all current messages
3. Each test starts with purging all topics involved in the tests using a setup() method annotated with @BeforeEach:
4. An actual test can verify the messages in a topic using the getMessages() method.
+
a. First makes an HTTP POST request, requesting the creation of a composite product.
b. Next, gets all messages from the three topics, one for each underlying core service.
c. For these tests, the specific timestamp for when an event was created is irrelevant. 
To be able to compare an actual event with an expected event, ignoring differenc-
es in the eventCreatedAt field, a helper class called IsSameEvent can be used. The 
sameEventExceptCreatedAt() method is a static method in the IsSameEvent class that 
compares Event objects and treats them as equal if all the fields are equal, except for 
the eventCreatedAt field.
d. Finally, it verifies that the expected events can be found, and no others.
+
[tabs]
====
microservices/composite/product/IsSameEvent.java::
+
[source, java]
----
package se.magnus.microservices.composite.product;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.core.type.TypeReference;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import java.io.IOException;
import java.util.HashMap;
import java.util.Map;
import org.hamcrest.Description;
import org.hamcrest.Matcher;
import org.hamcrest.TypeSafeMatcher;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import se.magnus.api.event.Event;

public class IsSameEvent extends TypeSafeMatcher<String> {

    private static final Logger LOG = LoggerFactory.getLogger(IsSameEvent.class);

    private ObjectMapper mapper = new ObjectMapper();

    private Event expectedEvent;

    private IsSameEvent(Event expectedEvent) {
        this.expectedEvent = expectedEvent;
    }

    @Override
    protected boolean matchesSafely(String eventAsJson) {

        if (expectedEvent == null) {
            return false;
        }

        LOG.trace("Convert the following json string to a map: {}", eventAsJson);
        Map mapEvent = convertJsonStringToMap(eventAsJson);
        mapEvent.remove("eventCreatedAt");

        Map mapExpectedEvent = getMapWithoutCreatedAt(expectedEvent);

        LOG.trace("Got the map: {}", mapEvent);
        LOG.trace("Compare to the expected map: {}", mapExpectedEvent);
        return mapEvent.equals(mapExpectedEvent);
    }

    @Override
    public void describeTo(Description description) {
        String expectedJson = convertObjectToJsonString(expectedEvent);
        description.appendText("expected to look like " + expectedJson);
    }

    public static Matcher<String> sameEventExceptCreatedAt(Event expectedEvent) {
        return new IsSameEvent(expectedEvent);
    }

    private Map getMapWithoutCreatedAt(Event event) {
        Map mapEvent = convertObjectToMap(event);
        mapEvent.remove("eventCreatedAt");
        return mapEvent;
    }

    private Map convertObjectToMap(Object object) {
        JsonNode node = mapper.convertValue(object, JsonNode.class);
        return mapper.convertValue(node, Map.class);
    }

    private String convertObjectToJsonString(Object object) {
        try {
            return mapper.writeValueAsString(object);
        } catch (JsonProcessingException e) {
            throw new RuntimeException(e);
        }
    }

    private Map convertJsonStringToMap(String eventAsJson) {
        try {
            return mapper.readValue(eventAsJson, new TypeReference<HashMap>() {
            });
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }
}
----

microservices/composite/product/MessagingTests.java::
+
[source, java]
----
package se.magnus.microservices.composite.product;

import static java.util.Collections.singletonList;
import static org.hamcrest.MatcherAssert.assertThat;
import static org.hamcrest.Matchers.is;
import static org.junit.jupiter.api.Assertions.assertEquals;
import static org.springframework.boot.test.context.SpringBootTest.WebEnvironment.RANDOM_PORT;
import static org.springframework.http.HttpStatus.ACCEPTED;
import static reactor.core.publisher.Mono.just;
import static se.magnus.api.event.Event.Type.CREATE;
import static se.magnus.api.event.Event.Type.DELETE;
import static se.magnus.microservices.composite.product.IsSameEvent.sameEventExceptCreatedAt;

import java.util.ArrayList;
import java.util.List;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.cloud.stream.binder.test.OutputDestination;
import org.springframework.cloud.stream.binder.test.TestChannelBinderConfiguration;
import org.springframework.context.annotation.Import;
import org.springframework.http.HttpStatus;
import org.springframework.messaging.Message;
import org.springframework.test.web.reactive.server.WebTestClient;
import se.magnus.api.composite.product.ProductAggregate;
import se.magnus.api.composite.product.RecommendationSummary;
import se.magnus.api.composite.product.ReviewSummary;
import se.magnus.api.core.product.Product;
import se.magnus.api.core.recommendation.Recommendation;
import se.magnus.api.core.review.Review;
import se.magnus.api.event.Event;

@SpringBootTest(webEnvironment = RANDOM_PORT, properties = { "spring.main.allow-bean-definition-overriding=true" })
@Import({ TestChannelBinderConfiguration.class })
class MessagingTests {

    private static final Logger LOG = LoggerFactory.getLogger(MessagingTests.class);

    @Autowired
    private WebTestClient client;

    @Autowired
    private OutputDestination target;

    @BeforeEach
    void setUp() {
        purgeMessages("products");
        purgeMessages("recommendations");
        purgeMessages("reviews");
    }

    @Test
    void createCompositeProduct1() {

        ProductAggregate composite = new ProductAggregate(1, "name", 1, null, null, null);
        postAndVerifyProduct(composite, ACCEPTED);

        final List<String> productMessages = getMessages("products");
        final List<String> recommendationMessages = getMessages("recommendations");
        final List<String> reviewMessages = getMessages("reviews");

        // Assert one expected new product event queued up
        assertEquals(1, productMessages.size());

        Event<Integer, Product> expectedEvent = new Event(CREATE, composite.getProductId(),
                new Product(composite.getProductId(), composite.getName(), composite.getWeight(), null));
        assertThat(productMessages.get(0), is(sameEventExceptCreatedAt(expectedEvent)));

        // Assert no recommendation and review events
        assertEquals(0, recommendationMessages.size());
        assertEquals(0, reviewMessages.size());
    }

    @Test
    void createCompositeProduct2() {

        ProductAggregate composite = new ProductAggregate(1, "name", 1,
                singletonList(new RecommendationSummary(1, "a", 1, "c")),
                singletonList(new ReviewSummary(1, "a", "s", "c")), null);
        postAndVerifyProduct(composite, ACCEPTED);

        final List<String> productMessages = getMessages("products");
        final List<String> recommendationMessages = getMessages("recommendations");
        final List<String> reviewMessages = getMessages("reviews");

        // Assert one create product event queued up
        assertEquals(1, productMessages.size());

        Event<Integer, Product> expectedProductEvent = new Event(CREATE, composite.getProductId(),
                new Product(composite.getProductId(), composite.getName(), composite.getWeight(), null));
        assertThat(productMessages.get(0), is(sameEventExceptCreatedAt(expectedProductEvent)));

        // Assert one create recommendation event queued up
        assertEquals(1, recommendationMessages.size());

        RecommendationSummary rec = composite.getRecommendations().get(0);
        Event<Integer, Product> expectedRecommendationEvent = new Event(CREATE, composite.getProductId(),
                new Recommendation(composite.getProductId(), rec.getRecommendationId(), rec.getAuthor(), rec.getRate(),
                        rec.getContent(), null));
        assertThat(recommendationMessages.get(0), is(sameEventExceptCreatedAt(expectedRecommendationEvent)));

        // Assert one create review event queued up
        assertEquals(1, reviewMessages.size());

        ReviewSummary rev = composite.getReviews().get(0);
        Event<Integer, Product> expectedReviewEvent = new Event(CREATE, composite.getProductId(),
                new Review(composite.getProductId(), rev.getReviewId(), rev.getAuthor(), rev.getSubject(),
                        rev.getContent(), null));
        assertThat(reviewMessages.get(0), is(sameEventExceptCreatedAt(expectedReviewEvent)));
    }

    @Test
    void deleteCompositeProduct() {
        deleteAndVerifyProduct(1, ACCEPTED);

        final List<String> productMessages = getMessages("products");
        final List<String> recommendationMessages = getMessages("recommendations");
        final List<String> reviewMessages = getMessages("reviews");

        // Assert one delete product event queued up
        assertEquals(1, productMessages.size());

        Event<Integer, Product> expectedProductEvent = new Event(DELETE, 1, null);
        assertThat(productMessages.get(0), is(sameEventExceptCreatedAt(expectedProductEvent)));

        // Assert one delete recommendation event queued up
        assertEquals(1, recommendationMessages.size());

        Event<Integer, Product> expectedRecommendationEvent = new Event(DELETE, 1, null);
        assertThat(recommendationMessages.get(0), is(sameEventExceptCreatedAt(expectedRecommendationEvent)));

        // Assert one delete review event queued up
        assertEquals(1, reviewMessages.size());

        Event<Integer, Product> expectedReviewEvent = new Event(DELETE, 1, null);
        assertThat(reviewMessages.get(0), is(sameEventExceptCreatedAt(expectedReviewEvent)));
    }

    private void purgeMessages(String bindingName) {
        getMessages(bindingName);
    }

    private List<String> getMessages(String bindingName) {
        List<String> messages = new ArrayList<>();
        boolean anyMoreMessages = true;

        while (anyMoreMessages) {
            Message<byte[]> message = getMessage(bindingName);

            if (message == null) {
                anyMoreMessages = false;

            } else {
                messages.add(new String(message.getPayload()));
            }
        }
        return messages;
    }

    private Message<byte[]> getMessage(String bindingName) {
        try {
            return target.receive(0, bindingName);
        } catch (NullPointerException npe) {
            // If the messageQueues member variable in the target object contains no queues
            // when the receive method is called, it will cause a NPE to be thrown.
            // So we catch the NPE here and return null to indicate that no messages were
            // found.
            LOG.error("getMessage() received a NPE with binding = {}", bindingName);
            return null;
        }
    }

    private void postAndVerifyProduct(ProductAggregate compositeProduct, HttpStatus expectedStatus) {
        client.post()
                .uri("/product-composite")
                .body(just(compositeProduct), ProductAggregate.class)
                .exchange()
                .expectStatus().isEqualTo(expectedStatus);
    }

    private void deleteAndVerifyProduct(int productId, HttpStatus expectedStatus) {
        client.delete()
                .uri("/product-composite/" + productId)
                .exchange()
                .expectStatus().isEqualTo(expectedStatus);
    }
}
----
====

Polar Book Shop::
+
[source, java]
----
----
======

=== Testing Consumer
To be able to call the message processor from the test class, we inject the message processor bean 
into a member variable, we not only inject any Consumer function but also use the 
@Qualifier annotation to specify that we want to inject the Consumer function that has the name 
messageProcessor:
[source,java,attributes]
----
@SpringBootTest
class ProductServiceApplicationTests {
  @Autowired
  @Qualifier("messageProcessor")
  private Consumer<Event<Integer, Product>> messageProcessor;
----

[tabs]
======

CaveatEmptor::
+
[tabs]
====

Country.java::
+
[source, java]
----
----
====

Cities API::
+
[tabs]
====
Country.java::
+
[source, java]
----
----
====

Multiplication microservices::
+
[source, java]
----
----

Microservices with Spring Boot 3 and Spring Cloud::
+
To send create and delete events to the message processor, we add two helper methods, `sendCreateProductEvent` and `sendDeleteProductEvent`, Note that we use the accept() method in the Consumer function interface declaration to invoke the 
message processor. This means that we skip the messaging system in the tests and call the message 
processor directly.
+
The tests for creating and deleting entities are updated to use these helper methods.
[tabs]
====
ProductServiceApplicationTests.java::
+
[source, java]
----
package se.magnus.microservices.core.product;

import static org.junit.jupiter.api.Assertions.*;
import static org.springframework.boot.test.context.SpringBootTest.WebEnvironment.RANDOM_PORT;
import static org.springframework.http.HttpStatus.*;
import static org.springframework.http.MediaType.APPLICATION_JSON;
import static se.magnus.api.event.Event.Type.CREATE;
import static se.magnus.api.event.Event.Type.DELETE;

import java.util.function.Consumer;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.http.HttpStatus;
import org.springframework.test.web.reactive.server.WebTestClient;
import se.magnus.api.core.product.Product;
import se.magnus.api.event.Event;
import se.magnus.api.exceptions.InvalidInputException;
import se.magnus.microservices.core.product.persistence.MongoDbTestBase;
import se.magnus.microservices.core.product.persistence.ProductRepository;

@SpringBootTest(webEnvironment = RANDOM_PORT)
class ProductServiceApplicationTests extends MongoDbTestBase {

  @Autowired
  private WebTestClient client;

  @Autowired
  private ProductRepository repository;

  @Autowired
  @Qualifier("messageProcessor")
  private Consumer<Event<Integer, Product>> messageProcessor;

  @BeforeEach
  void setupDb() {
    repository.deleteAll().block();
  }

  @Test
  void getProductById() {

    int productId = 1;

    assertNull(repository.findByProductId(productId).block());
    assertEquals(0, (long)repository.count().block());

    sendCreateProductEvent(productId);

    assertNotNull(repository.findByProductId(productId).block());
    assertEquals(1, (long)repository.count().block());

    getAndVerifyProduct(productId, OK)
      .jsonPath("$.productId").isEqualTo(productId);
  }

  @Test
  void duplicateError() {

    int productId = 1;

    assertNull(repository.findByProductId(productId).block());

    sendCreateProductEvent(productId);

    assertNotNull(repository.findByProductId(productId).block());

    InvalidInputException thrown = assertThrows(
      InvalidInputException.class,
      () -> sendCreateProductEvent(productId),
      "Expected a InvalidInputException here!");
    assertEquals("Duplicate key, Product Id: " + productId, thrown.getMessage());
  }

  @Test
  void deleteProduct() {

    int productId = 1;

    sendCreateProductEvent(productId);
    assertNotNull(repository.findByProductId(productId).block());

    sendDeleteProductEvent(productId);
    assertNull(repository.findByProductId(productId).block());

    sendDeleteProductEvent(productId);
  }

  @Test
  void getProductInvalidParameterString() {

    getAndVerifyProduct("/no-integer", BAD_REQUEST)
      .jsonPath("$.path").isEqualTo("/product/no-integer")
      .jsonPath("$.message").isEqualTo("Type mismatch.");
  }

  @Test
  void getProductNotFound() {

    int productIdNotFound = 13;
    getAndVerifyProduct(productIdNotFound, NOT_FOUND)
      .jsonPath("$.path").isEqualTo("/product/" + productIdNotFound)
      .jsonPath("$.message").isEqualTo("No product found for productId: " + productIdNotFound);
  }

  @Test
  void getProductInvalidParameterNegativeValue() {

    int productIdInvalid = -1;

    getAndVerifyProduct(productIdInvalid, UNPROCESSABLE_ENTITY)
      .jsonPath("$.path").isEqualTo("/product/" + productIdInvalid)
      .jsonPath("$.message").isEqualTo("Invalid productId: " + productIdInvalid);
  }

  private WebTestClient.BodyContentSpec getAndVerifyProduct(int productId, HttpStatus expectedStatus) {
    return getAndVerifyProduct("/" + productId, expectedStatus);
  }

  private WebTestClient.BodyContentSpec getAndVerifyProduct(String productIdPath, HttpStatus expectedStatus) {
    return client.get()
      .uri("/product" + productIdPath)
      .accept(APPLICATION_JSON)
      .exchange()
      .expectStatus().isEqualTo(expectedStatus)
      .expectHeader().contentType(APPLICATION_JSON)
      .expectBody();
  }

  private void sendCreateProductEvent(int productId) {
    Product product = new Product(productId, "Name " + productId, productId, "SA");
    Event<Integer, Product> event = new Event(CREATE, productId, product);
    messageProcessor.accept(event);
  }

  private void sendDeleteProductEvent(int productId) {
    Event<Integer, Product> event = new Event(DELETE, productId, null);
    messageProcessor.accept(event);
  }
}
----

RecommendationServiceApplicationTests::
+
[source, java]
----
package se.magnus.microservices.core.recommendation;

import static org.junit.jupiter.api.Assertions.*;
import static org.springframework.boot.test.context.SpringBootTest.WebEnvironment.RANDOM_PORT;
import static org.springframework.http.HttpStatus.*;
import static org.springframework.http.MediaType.APPLICATION_JSON;
import static se.magnus.api.event.Event.Type.CREATE;
import static se.magnus.api.event.Event.Type.DELETE;

import java.util.function.Consumer;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.http.HttpStatus;
import org.springframework.test.web.reactive.server.WebTestClient;
import se.magnus.api.core.recommendation.Recommendation;
import se.magnus.api.event.Event;
import se.magnus.api.exceptions.InvalidInputException;
import se.magnus.microservices.core.recommendation.persistence.MongoDbTestBase;
import se.magnus.microservices.core.recommendation.persistence.RecommendationRepository;

@SpringBootTest(webEnvironment = RANDOM_PORT)
class RecommendationServiceApplicationTests extends MongoDbTestBase {

	@Autowired
	private WebTestClient client;

	@Autowired
	private RecommendationRepository repository;

	@Autowired
	@Qualifier("messageProcessor")
	private Consumer<Event<Integer, Recommendation>> messageProcessor;

	@BeforeEach
	void setupDb() {
		repository.deleteAll().block();
	}

	@Test
	void getRecommendationsByProductId() {

		int productId = 1;

		sendCreateRecommendationEvent(productId, 1);
		sendCreateRecommendationEvent(productId, 2);
		sendCreateRecommendationEvent(productId, 3);

		assertEquals(3, (long) repository.findByProductId(productId).count().block());

		getAndVerifyRecommendationsByProductId(productId, OK)
				.jsonPath("$.length()").isEqualTo(3)
				.jsonPath("$[2].productId").isEqualTo(productId)
				.jsonPath("$[2].recommendationId").isEqualTo(3);
	}

	@Test
	void duplicateError() {

		int productId = 1;
		int recommendationId = 1;

		sendCreateRecommendationEvent(productId, recommendationId);

		assertEquals(1, (long) repository.count().block());

		InvalidInputException thrown = assertThrows(
				InvalidInputException.class,
				() -> sendCreateRecommendationEvent(productId, recommendationId),
				"Expected a InvalidInputException here!");
		assertEquals("Duplicate key, Product Id: 1, Recommendation Id:1", thrown.getMessage());

		assertEquals(1, (long) repository.count().block());
	}

	@Test
	void deleteRecommendations() {

		int productId = 1;
		int recommendationId = 1;

		sendCreateRecommendationEvent(productId, recommendationId);
		assertEquals(1, (long) repository.findByProductId(productId).count().block());

		sendDeleteRecommendationEvent(productId);
		assertEquals(0, (long) repository.findByProductId(productId).count().block());

		sendDeleteRecommendationEvent(productId);
	}

	@Test
	void getRecommendationsMissingParameter() {

		getAndVerifyRecommendationsByProductId("", BAD_REQUEST)
				.jsonPath("$.path").isEqualTo("/recommendation")
				.jsonPath("$.message").isEqualTo("Required query parameter 'productId' is not present.");
	}

	@Test
	void getRecommendationsInvalidParameter() {

		getAndVerifyRecommendationsByProductId("?productId=no-integer", BAD_REQUEST)
				.jsonPath("$.path").isEqualTo("/recommendation")
				.jsonPath("$.message").isEqualTo("Type mismatch.");
	}

	@Test
	void getRecommendationsNotFound() {

		getAndVerifyRecommendationsByProductId("?productId=113", OK)
				.jsonPath("$.length()").isEqualTo(0);
	}

	@Test
	void getRecommendationsInvalidParameterNegativeValue() {

		int productIdInvalid = -1;

		getAndVerifyRecommendationsByProductId("?productId=" + productIdInvalid, UNPROCESSABLE_ENTITY)
				.jsonPath("$.path").isEqualTo("/recommendation")
				.jsonPath("$.message").isEqualTo("Invalid productId: " + productIdInvalid);
	}

	private WebTestClient.BodyContentSpec getAndVerifyRecommendationsByProductId(int productId,
			HttpStatus expectedStatus) {
		return getAndVerifyRecommendationsByProductId("?productId=" + productId, expectedStatus);
	}

	private WebTestClient.BodyContentSpec getAndVerifyRecommendationsByProductId(String productIdQuery,
			HttpStatus expectedStatus) {
		return client.get()
				.uri("/recommendation" + productIdQuery)
				.accept(APPLICATION_JSON)
				.exchange()
				.expectStatus().isEqualTo(expectedStatus)
				.expectHeader().contentType(APPLICATION_JSON)
				.expectBody();
	}

	private void sendCreateRecommendationEvent(int productId, int recommendationId) {
		Recommendation recommendation = new Recommendation(productId, recommendationId, "Author " + recommendationId,
				recommendationId, "Content " + recommendationId, "SA");
		Event<Integer, Recommendation> event = new Event(CREATE, productId, recommendation);
		messageProcessor.accept(event);
	}

	private void sendDeleteRecommendationEvent(int productId) {
		Event<Integer, Recommendation> event = new Event(DELETE, productId, null);
		messageProcessor.accept(event);
	}
}
----

ReviewServiceApplicationTests.java::
+
[source, java]
----
package se.magnus.microservices.core.review;

import static org.junit.jupiter.api.Assertions.*;
import static org.springframework.boot.test.context.SpringBootTest.WebEnvironment.RANDOM_PORT;
import static org.springframework.http.HttpStatus.*;
import static org.springframework.http.MediaType.APPLICATION_JSON;
import static se.magnus.api.event.Event.Type.CREATE;
import static se.magnus.api.event.Event.Type.DELETE;

import java.util.function.Consumer;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.http.HttpStatus;
import org.springframework.test.web.reactive.server.WebTestClient;
import se.magnus.api.core.review.Review;
import se.magnus.api.event.Event;
import se.magnus.api.exceptions.InvalidInputException;
import se.magnus.microservices.core.review.persistence.DBTestBase;
import se.magnus.microservices.core.review.persistence.ReviewRepository;

@SpringBootTest(webEnvironment = RANDOM_PORT, properties = {
  "spring.cloud.stream.defaultBinder=rabbit",
  "logging.level.se.magnus=DEBUG"})
class ReviewServiceApplicationTests extends DBTestBase {

  @Autowired
  private WebTestClient client;

  @Autowired
  private ReviewRepository repository;

  @Autowired
  @Qualifier("messageProcessor")
  private Consumer<Event<Integer, Review>> messageProcessor;

  @BeforeEach
  void setupDb() {
    repository.deleteAll();
  }

  @Test
  void getReviewsByProductId() {

    int productId = 1;

    assertEquals(0, repository.findByProductId(productId).size());

    sendCreateReviewEvent(productId, 1);
    sendCreateReviewEvent(productId, 2);
    sendCreateReviewEvent(productId, 3);

    assertEquals(3, repository.findByProductId(productId).size());

    getAndVerifyReviewsByProductId(productId, OK)
      .jsonPath("$.length()").isEqualTo(3)
      .jsonPath("$[2].productId").isEqualTo(productId)
      .jsonPath("$[2].reviewId").isEqualTo(3);
  }

  @Test
  void duplicateError() {

    int productId = 1;
    int reviewId = 1;

    assertEquals(0, repository.count());

    sendCreateReviewEvent(productId, reviewId);

    assertEquals(1, repository.count());

    InvalidInputException thrown = assertThrows(
      InvalidInputException.class,
      () -> sendCreateReviewEvent(productId, reviewId),
      "Expected a InvalidInputException here!");
    assertEquals("Duplicate key, Product Id: 1, Review Id:1", thrown.getMessage());

    assertEquals(1, repository.count());
  }

  @Test
  void deleteReviews() {

    int productId = 1;
    int reviewId = 1;

    sendCreateReviewEvent(productId, reviewId);
    assertEquals(1, repository.findByProductId(productId).size());

    sendDeleteReviewEvent(productId);
    assertEquals(0, repository.findByProductId(productId).size());

    sendDeleteReviewEvent(productId);
  }

  @Test
  void getReviewsMissingParameter() {

    getAndVerifyReviewsByProductId("", BAD_REQUEST)
      .jsonPath("$.path").isEqualTo("/review")
      .jsonPath("$.message").isEqualTo("Required query parameter 'productId' is not present.");
  }

  @Test
  void getReviewsInvalidParameter() {

    getAndVerifyReviewsByProductId("?productId=no-integer", BAD_REQUEST)
      .jsonPath("$.path").isEqualTo("/review")
      .jsonPath("$.message").isEqualTo("Type mismatch.");
  }

  @Test
  void getReviewsNotFound() {

    getAndVerifyReviewsByProductId("?productId=213", OK)
      .jsonPath("$.length()").isEqualTo(0);
  }

  @Test
  void getReviewsInvalidParameterNegativeValue() {

    int productIdInvalid = -1;

    getAndVerifyReviewsByProductId("?productId=" + productIdInvalid, UNPROCESSABLE_ENTITY)
      .jsonPath("$.path").isEqualTo("/review")
      .jsonPath("$.message").isEqualTo("Invalid productId: " + productIdInvalid);
  }

  private WebTestClient.BodyContentSpec getAndVerifyReviewsByProductId(int productId, HttpStatus expectedStatus) {
    return getAndVerifyReviewsByProductId("?productId=" + productId, expectedStatus);
  }

  private WebTestClient.BodyContentSpec getAndVerifyReviewsByProductId(String productIdQuery, HttpStatus expectedStatus) {
    return client.get()
      .uri("/review" + productIdQuery)
      .accept(APPLICATION_JSON)
      .exchange()
      .expectStatus().isEqualTo(expectedStatus)
      .expectHeader().contentType(APPLICATION_JSON)
      .expectBody();
  }

  private void sendCreateReviewEvent(int productId, int reviewId) {
    Review review = new Review(productId, reviewId, "Author " + reviewId, "Subject " + reviewId, "Content " + reviewId, "SA");
    Event<Integer, Review> event = new Event(CREATE, productId, review);
    messageProcessor.accept(event);
  }

  private void sendDeleteReviewEvent(int productId) {
    Event<Integer, Review> event = new Event(DELETE, productId, null);
    messageProcessor.accept(event);
  }
}
----
====

Polar Book Shop::
+
[source, java]
----
----
======


[tabs]
======

Calaculator Example::
+
[tabs]
====

Country.java::
+
[source, java]
----
----
====

Another Example::
+
[source, java]
----
----

======

=== Running manual tests of the reactive microservice landscape
Since RabbitMQ 
can be used both with and without partitions, we will test both cases. Three different configurations 
will be used, each defined in a separate Docker Compose file:

• Using RabbitMQ without the use of partitions
• Using RabbitMQ with two partitions per topic
• Using Kafka with two partitions per topic

However, before testing these three configurations, we need to add two features to be able to test the 
asynchronous processing:

• Saving events for later inspection when using RabbitMQ
• A health API that can be used to monitor the state of the microservice landscape

=== Saving events
After running some tests on event-driven asynchronous services, it might be of interest to see what 
events were actually sent. When using Spring Cloud Stream with Kafka, events are retained in the 
topics, even after consumers have processed them. However, when using Spring Cloud Stream with 
RabbitMQ, the events are removed after they have been processed successfully.

To be able to see what events have been published on each topic, Spring Cloud Stream is configured 
to save published events in a separate consumer group, auditGroup, per topic. For the products topic, 
the configuration looks like the following:
[source,yml,attributes]
----
spring.cloud.stream:
  bindings:
    products-out-0:
      destination: products
      producer:
        required-groups: auditGroup
----
When using RabbitMQ, this will result in extra queues being created where the events are stored for later inspection.

== Using RabbitMQ without using partitions

[tabs]
======

CaveatEmptor::
+
[tabs]
====

Country.java::
+
[source, java]
----
----
====

Cities API::
+
[tabs]
====
Country.java::
+
[source, java]
----
----
====

Multiplication microservices::
+
[source, java]
----
----

Microservices with Spring Boot 3 and Spring Cloud::
+
The default docker-compose.yml Docker Compose file is used for this configuration.
+
[source,yml,attributes]
----
  rabbitmq:
    image: rabbitmq:3.11.8-management
    mem_limit: 512m
    ports:
      - 5672:5672
      - 15672:15672
    healthcheck:
      test: ["CMD", "rabbitmqctl", "status"]
      interval: 5s
      timeout: 2s
      retries: 60
----

To run manual tests, perform the following steps:

1. Build and start the system landscape with the following commands:
 ./gradlew build && docker compose build && docker compose up -d
2. Now, we have to wait for the microservice landscape to be up and running. Try running 
the following command a few times:
+
 curl -s localhost:8080/actuator/health | jq -r .status
+
When it returns UP, we are ready to run our tests!
3. First, create a composite product with the following commands:
+
body='{"productId":1,"name":"product name C","weight":300,
 "recommendations":[
{"recommendationId":1,"author":"author 1",
"rate":1,"content":"content 1"},
 {"recommendationId":2,"author":"author 2",
"rate":2,"content":"content 2"},
 {"recommendationId":3,"author":"author 3",
"rate":3,"content":"content 3"}
], "reviews":[
 {"reviewId":1,"author":"author 1","subject":"subject 1",
"content":"content 1"},
 {"reviewId":2,"author":"author 2","subject":"subject 2",
"content":"content 2"},
 {"reviewId":3,"author":"author 3","subject":"subject 3",
"content":"content 3"}
]}'
+
curl -X POST localhost:8080/product-composite -H "Content-Type: application/json" --data "$body"
+
When using Spring Cloud Stream together with RabbitMQ, it will create one RabbitMQ 
exchange per topic and a set of queues, depending on our configuration. Let’s see what 
queues Spring Cloud Stream has created for us!
4. Open the following URL in a web browser: http://localhost:15672/#/queues. Log in 
with the default username/password guest/guest. You should see the following queues:
For each topic, we can see one queue for auditGroup, one queue for the consumer group 
that’s used by the corresponding core microservice, and one dead-letter queue. We can 
also see that the auditGroup queues contain messages, as expected!
5. Click on the products.auditGroup queue and scroll down to the Get messages section, 
expand it, and click on the button named Get Message(s) to see the message in the queue:
From the preceding screenshot, note the Payload section but also the header, partition-
Key, which we will use in the next section where we try out RabbitMQ with partitions.
6. Next, try to get the product composite using the following code:
+
 curl -s localhost:8080/product-composite/1 | jq
+
7. Finally, delete it with the following command:
+
 curl -X DELETE localhost:8080/product-composite/1
+
8. Try to get the deleted product again. It should result in a 404 - "NotFound" response!
9. If you look in the RabbitMQ audit queues again, you should be able to find new messages 
containing delete events.
10. Wrap up the test by bringing down the microservice landscape with the following com-
mand:
docker compose down

Polar Book Shop::
+
[source, java]
----
----
======

== Using RabbitMQ with partitions

[tabs]
======

CaveatEmptor::
+
[tabs]
====

Country.java::
+
[source, java]
----
----
====

Cities API::
+
[tabs]
====
Country.java::
+
[source, java]
----
----
====

Multiplication microservices::
+
[source, java]
----
----

Microservices with Spring Boot 3 and Spring Cloud::
+
We have a separate Docker Compose file prepared for using RabbitMQ with two partitions per 
topic: docker-compose-partitions.yml. It will also start two instances per core microservice, 
one for each partition.
+
1. Start up the microservice landscape with the following command:
+
 docker compose build && docker compose up -d
+
2. Now, we have to wait for the microservice landscape to be up and running. Try running 
the following command a few times:
+
 curl -s localhost:8080/actuator/health | jq -r .status
+
When it returns UP, we are ready to run our tests!
3. First, create a composite product with the following commands:
+
body='{"productId":1,"name":"product name 1","weight":100,
 "recommendations":[
{"recommendationId":1,"author":"author 1",
"rate":1,"content":"content 1"},
 {"recommendationId":2,"author":"author 2",
"rate":2,"content":"content 2"},
 {"recommendationId":3,"author":"author 3",
"rate":3,"content":"content 3"}
], "reviews":[
 {"reviewId":1,"author":"author 1","subject":"subject 1",
"content":"content 1"},
 {"reviewId":2,"author":"author 2","subject":"subject 2",
"content":"content 2"},
 {"reviewId":3,"author":"author 3","subject":"subject 3",
"content":"content 3"}
]}'
+
curl -X POST localhost:8080/product-composite -H "Content-Type: application/json" --data "$body"
+
4.  also create a composite product with the product ID set to 2
+
body='{"productId":2,"name":"product name 2","weight":200,
 "recommendations":[
{"recommendationId":1,"author":"author 1",
"rate":1,"content":"content 1"},
 {"recommendationId":2,"author":"author 2",
"rate":2,"content":"content 2"},
 {"recommendationId":3,"author":"author 3",
"rate":3,"content":"content 3"}
], "reviews":[
 {"reviewId":1,"author":"author 1","subject":"subject 1",
"content":"content 1"},
 {"reviewId":2,"author":"author 2","subject":"subject 2",
"content":"content 2"},
 {"reviewId":3,"author":"author 3","subject":"subject 3",
"content":"content 3"}
]}'
+
curl -X POST localhost:8080/product-composite -H "Content-Type: application/json" --data "$body"
+
4. If you take a look at the queues set up by 
Spring Cloud Stream, you will see one queue per partition and that the product audit queues now 
contain one message each; the event for product ID 1 was placed in one partition and the event 
for product ID 2 was placed in the other partition.
4. Open the following URL in a web browser: http://localhost:15672/#/queues. Log in 
with the default username/password guest/guest. You should see the following queues:
[tabs]
====
docker-compose-partitions.yml::
• To make all microservice instances aware that they will use partitions, we have added the 
Spring profile, streaming_partitioned, to their SPRING_PROFILES_ACTIVE environment 
variable.
• We assign the two product instances to different partitions using different Spring pro-
files. The streaming_instance_0 Spring profile is used by the first product instance and 
streaming_instance_1 is used by the second instance, product-p1.
• The second product instance will only process asynchronous events; it will not respond 
to API calls. Since it has a different name, product-p1 (also used as its DNS name), it will 
not respond to calls to a URL starting with http://product:8080.
+
[source, yml]
----
version: "2.1"

services:
  product:
    build: microservices/product-service
    mem_limit: 512m
    environment:
      - SPRING_PROFILES_ACTIVE=docker,streaming_partitioned,streaming_instance_0
    depends_on:
      mongodb:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  product-p1:
    build: microservices/product-service
    mem_limit: 512m
    environment:
      - SPRING_PROFILES_ACTIVE=docker,streaming_partitioned,streaming_instance_1
    depends_on:
      mongodb:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  recommendation:
    build: microservices/recommendation-service
    mem_limit: 512m
    environment:
      - SPRING_PROFILES_ACTIVE=docker,streaming_partitioned,streaming_instance_0
    depends_on:
      mongodb:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  recommendation-p1:
    build: microservices/recommendation-service
    mem_limit: 512m
    environment:
      - SPRING_PROFILES_ACTIVE=docker,streaming_partitioned,streaming_instance_1
    depends_on:
      mongodb:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  review:
    build: microservices/review-service
    mem_limit: 512m
    environment:
      - SPRING_PROFILES_ACTIVE=docker,streaming_partitioned,streaming_instance_0
    depends_on:
      mysql:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  review-p1:
    build: microservices/review-service
    mem_limit: 512m
    environment:
      - SPRING_PROFILES_ACTIVE=docker,streaming_partitioned,streaming_instance_1
    depends_on:
      mysql:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  product-composite:
    build: microservices/product-composite-service
    mem_limit: 512m
    ports:
      - "8080:8080"
    environment:
      - SPRING_PROFILES_ACTIVE=docker,streaming_partitioned
    depends_on:
      rabbitmq:
        condition: service_healthy

  mongodb:
    image: mongo:6.0.4
    mem_limit: 512m
    ports:
      - "27017:27017"
    command: mongod
    healthcheck:
      test: "mongostat -n 1"
      interval: 5s
      timeout: 2s
      retries: 60

  mysql:
    image: mysql:8.0.32
    mem_limit: 512m
    ports:
      - "3306:3306"
    environment:
      - MYSQL_ROOT_PASSWORD=rootpwd
      - MYSQL_DATABASE=review-db
      - MYSQL_USER=user
      - MYSQL_PASSWORD=pwd
    healthcheck:
      test: '/usr/bin/mysql --user=user --password=pwd --execute "SHOW DATABASES;"'
      interval: 5s
      timeout: 2s
      retries: 60

  rabbitmq:
    image: rabbitmq:3.11.8-management
    mem_limit: 512m
    ports:
      - 5672:5672
      - 15672:15672
    healthcheck:
      test: ["CMD", "rabbitmqctl", "status"]
      interval: 5s
      timeout: 2s
      retries: 60
----

application.yml::
+
[source, yml]
----
spring.config.activate.on-profile: streaming_partitioned

spring.cloud.stream.bindings.messageProcessor-in-0.consumer:
  partitioned: true
  instanceCount: 2

---
spring.config.activate.on-profile: streaming_instance_0

spring.cloud.stream.bindings.messageProcessor-in-0.consumer.instanceIndex: 0

---
spring.config.activate.on-profile: streaming_instance_1

spring.cloud.stream.bindings.messageProcessor-in-0.consumer.instanceIndex: 1

----
====

Polar Book Shop::
+
[source, java]
----
----
======